---
title: "Analysis 4: von Bertalanffy Individual Growth Analysis"
author: "Joe Gunn"
date: "2023-04-28"
output: html_document
---

# Project: Effects of admixture on fitness in Neosho Bass populations 
<font size="+1">We assessed the effect of admixture on fitness in two stream populations within the native range of the Neosho Bass (<i>M. velox</i>) which are known to have extensively hybridized with Smallmouth Bass (<i>Micropterus dolomieu</i>). Specifically, we used 14 microsatellite loci in a Bayesian analysis of population structure to estimate proportions of interspecific ancestry in individuals collected from Big Sugar Creek and the Elk River in southwestern Missouri (Central Interior Highlands ecoregion (CIH), North America). We used ancestry inference to identify fish as "Pure Neosho Bass", "Pure Smallmouth Bass", or "Admixed". For each group, we measured age and total length and projected individual growth using the standard parameterization of the von Berlanffy growth model, comparing average theoretical maximum length among groups. Finally, we used body condition as a proxy of fitness and generated heterozygosity-fitness correlations of body condition across the global dataset, within stream populations, and within ancestry groups. We ultimately sought to understand the short-term genetic consequences of admixture for Neosho Bass populations in order to better inform management and long-term viability of distinct, economically and ecologically important sportfish species in the CIH.</font>

## Specific Aim: von Bertalanffy individual growth analysis
For this aim, parameterized the von Bertlanffy individual growth model for Neosho Bass in Big Sugar Creek and Elk River based on total length (tl_alive) and consensus age data to assess growth rates in inferred groups of interest. We started by using the Dahl-Lea linear back-calculation model We started by quantifying overall growth rate and maximum theoretical total length for all fish collected across both streams. Next, we quantified potential differences in growth by (1) individual sex (male or female) and (2) by stream (Big Sugar Creek or Elk River) to account for variation which may bias results in other groups. Finally, we assessed differences in growth based on ancestry group membership as inferred by STRUCTURE analysis in Analysis 3 (Neosho Bass, Smallmouth Bass, Admixed). For all growth assessments, we included linear back-calculated length-at-age estimates for large, older fish to increase sample size.

## Phases of Analysis
### Phase 1: Intra- and inter-observer error analysis for otolith annuli estimates
### Phase 2: Linear back-calculation
### Phase 3: von Bertlanffy growth analysis

### Libraries needed for analysis
```{r}
library(tidyverse)
library(cowplot)
library(readxl)
library(RFishBC)
library(rlist)
library(rstan)
library(bayesplot)
library(GGally)
library(scales)
```

## PHASE 1: INTRA- AND INTER-OBSERVER ERROR ANALYSIS FOR OTOLITH ANNULI ESTIMATES
In this phase of analysis, we conduct an analysis of intra- and inter-observer bias in estimating the number of otolith annuli on raw otolith microscope images. Three independent observers estimated the number annuli on each otolith image, and counts were compared among observers. If all observers agreed on annuli count for a given image, that count was used as the "consensus age". If there were discrepancies among two or three observers, a consensus age was determined by discussion.

### STEP 1: Select sets of otolith images consisting of a random 10% of the full dataset, to be re-counted by each observer (3 total observers); run the Rmd chunk below.
In this step, we selected sets of images at random, each including 10% of the original dataset (10% of 116 ~ 12 images per observer).

##### Select random sets of images:
```{r}
# Get vector of image names
otos <- c("FBS01.PNG","FBS02.PNG","FBS03.PNG","FBS04.PNG","FBS05.PNG","FBS06.PNG","FBS07.PNG","FBS08.PNG","FBS09.PNG","FBS10.PNG","FBS11.PNG","FBS12.PNG","FBS13.PNG","FBS14.PNG","FBS15.PNG","FBS16.PNG","FBS17.PNG","FBS18.PNG","FBS19.PNG","FBS20.PNG","FBS21.PNG","FBS22.PNG","FBS23.PNG","FBS24.PNG","FBS25.PNG","FBS26.PNG","FBS27.PNG","FBS28.PNG","FBS29.PNG","FBS30.PNG","FBS31.PNG","FBS32.PNG","FBS33.PNG","FBS34.PNG","FBS35.PNG","FBS36.PNG","FBS37.PNG","FBS38.PNG","FBS39.PNG","FBS40.PNG","FBS41.PNG","FBS42.PNG","FBS43.PNG","FBS44.PNG","FBS45.PNG","FBS46.PNG","FER01.PNG","FER02.PNG","FER03.PNG","FER04.PNG","FER05.PNG","FER06.PNG","FER07.PNG","FER08.PNG","FER09.PNG","FER10.PNG","FER11.PNG","FER12.PNG","FER13.PNG","FER14.PNG","FER15.PNG","FER16.PNG","FER17.PNG","FER18.PNG","FER19.PNG","FER20.PNG","FER21.PNG","FER22.PNG","FER23.PNG","FER24.PNG","FER25.PNG","FER26.PNG","FER27.PNG","FER28.PNG","FER29.PNG","FER30.PNG","FER31.PNG","FER32.PNG","FER33.PNG","FER34.PNG","FER35.PNG","FER36.PNG","FER37.PNG","FER38.PNG","FER39.PNG","FER40.PNG","FER41.PNG","FER42.PNG","FER43.PNG","FER44.PNG","FER45.PNG","FER46.PNG","FER48.PNG","FER49.PNG","FER50.PNG","FER51.PNG","FER52.PNG","FER53.PNG","FER54.PNG","FER55.PNG","FER56.PNG","FER57.PNG","FER58.PNG","FER59.PNG","FER60.PNG","FER61.PNG","FER62.PNG","FER63.PNG","FER64.PNG","FER65.PNG","FER66.PNG","FER68.PNG","FER69.PNG","FER70.PNG","FER71.PNG")

# Select 12 random images for recount by each observer
sample(otos, size = 12, replace = FALSE)
```

<b>Summary of sample sets for observers</b>:

<b>Joe</b>: FBS07.PNG, FER03.PNG, FBS40.PNG, FER39.PNG, FBS15.PNG, FER31.PNG, FBS17.PNG, FBS44.PNG, FER41.PNG, FBS37.PNG, FER65.PNG, FER11.PNG

<b>Eddie</b>: FBS07.PNG, FER06.PNG, FER19.PNG, FER07.PNG, FER20.PNG, FER35.PNG, FER43.PNG, FBS38.PNG, FER37.PNG, FBS06.PNG, FER55.PNG, FER16.PNG

<b>Michael</b>: FER54.PNG, FER48.PNG, FER33.PNG, FER34.PNG, FBS09.PNG, FBS03.PNG, FER62.PNG, FER60.PNG, FBS25.PNG, FBS24.PNG, FER70.PNG, FBS15.PNG

### STEP 2: Calculate intra-observer error
We calculated intra-observer error for each observer individually. We opted to calculate error as the number of discrepancies (number of individual samples for which there was a difference between the original annulus count on the sagittal otolith and the recount (which was conducted after 2 years)) divided by the total number of comparisons. 

Each observer recounted 12 randomly assigned samples (see STEP 1 above), so error was calculated as: error = discrepancies/12

We then calculated the mean of intra-observer error values across observers and reported this error in the final manuscript.

#### 2a: Prepare data for calculation; run the Rmd chunk below.

##### Prepare data for calculating intra-observer error:
```{r}
# Load in full ancestry data curated in Analysis 3 
load("../03_ancestry_analysis/data/processed_ancestry_data/full_ancestry_data.Rda")

# Read in recount data for eddie
eddie_recount <- read_excel("data/otolith_recounts/eddie_recount.xlsx")

# Read in recount data for joe
joe_recount <- read_excel("data/otolith_recounts/joe_recount.xlsx")

# Read in recount data for michael
michael_recount <- read_excel("data/otolith_recounts/michael_recount.xlsx")

# format recount data by converting sample ids to factors for eddie
eddie_recount <- eddie_recount %>%
  mutate(sample_id = factor(sample_id))

# format recount data by converting sample ids to factors for joe
joe_recount <- joe_recount %>%
  mutate(sample_id = factor(sample_id))

# format recount data by converting sample ids to factors for michael
michael_recount <- michael_recount %>%
  mutate(sample_id = factor(sample_id))

# Get original count data for eddie only
eddie_original <- full_ancestry_data %>%
  dplyr::select(sample_id, eddie_age)

# Get original count data for joe only
joe_original <- full_ancestry_data %>%
  dplyr::select(sample_id, joe_age)

# Get original count data for michael only
michael_original <- full_ancestry_data %>%
  dplyr::select(sample_id, michael_age)

# merge original and recount data for eddie
eddie <- merge(eddie_original, 
               eddie_recount, 
               by = "sample_id")

# rename second column
colnames(eddie)[2] <- c("age")

# merge original and recount data for joe
joe <- merge(joe_original,
             joe_recount, 
             by = "sample_id")

# rename second column
colnames(joe)[2] <- c("age")

# merge original and recount data for michael
michael <- merge(michael_original, 
                 michael_recount, 
                 by = "sample_id")

# rename second column
colnames(michael)[2] <- c("age")

# Save error datasets for downstream analyses
save(eddie, file = "data/otolith_recounts/eddie_error.Rda")
save(joe, file = "data/otolith_recounts/joe_error.Rda")
save(michael, file = "data/otolith_recounts/michael_error.Rda")
```

#### 2b: Calculate intra-observer error; run the Rmd chunk below.
In this step, we create columns in the recount data to represent difference between original age and recount estimates (0 if there are no differences, and 1 if there is a difference). We then calculate individual and average intra-observer error as described above.

##### Calculate intra-observer error:
```{r}
# Load error data
load("data/otolith_recounts/eddie_error.Rda")
load("data/otolith_recounts/joe_error.Rda")
load("data/otolith_recounts/michael_error.Rda")

# For eddie
eddie <- eddie %>%
  mutate(diff = as.numeric(ifelse(age == recount, "0", "1")),
         observer = factor(rep("eddie", times = nrow(eddie))))

# For joe
joe <- joe %>%
  mutate(diff = as.numeric(ifelse(age == recount, "0", "1")),
         observer = factor(rep("joe", times = nrow(joe))))

# For michael
michael <- michael %>%
  mutate(diff = as.numeric(ifelse(age == recount, "0", "1")),
         observer = factor(rep("michael", times = nrow(michael))))

# Rbind error datasets
error <- rbind(eddie,
               joe,
               michael)

# Calculate intra-observer error by dividing the number of count discrepancies by the total number of observations
error %>%
  group_by(observer) %>%
  summarize(intra_observer_error = mean(diff))

# Calculate average intra-observer error 
error %>%
   summarize(intra_observer_error = mean(diff))
```

We calculated an average intra-observer error of 0.05555556.

### STEP 3: Calculate inter-observer error; run the Rmd chunk below.
We calculated inter-observer error between each pair of observers (eddie and joe, eddie and michael, and michael and joe. We opted to calculate error as the number of discrepancies (number of individual samples for which there was a difference between the original observer annulus estimates) divided by the total number of comparisons. 

Each observer originally counted 116 samples (the full sample set), so error was calculated as: error = discrepancies/116

We then calculated the mean of inter-observer error values across inter-observer comparisons and reported this average error in the final manuscript.

#### 3a: Prepare data for calculation; run the Rmd chunk below.

##### Prepare data for calculating inter-observer error:
```{r}
# Load in full ancestry data curated in Analysis 3 
load("../03_ancestry_analysis/data/processed_ancestry_data/full_ancestry_data.Rda")

# Get original count data for eddie
eddie_original <- full_ancestry_data %>%
  select(sample_id, eddie_age)

# Get original count data for joe
joe_original <- full_ancestry_data %>%
  select(sample_id, joe_age)

# Get original count data for michael
michael_original <- full_ancestry_data %>%
  select(sample_id, michael_age)

# bind columns of counts from each observer
originals <- data.frame(cbind("eddie" = eddie_original[,-1],
                              "joe" = joe_original[,-1], 
                              "michael" = michael_original[,-1]))

# Drop NAs from data (SMB samples without age estimates)
originals <- originals %>%
  drop_na()

# Save original count data for downstream analyses
save(originals, file = "data/otolith_recounts/originals.Rda")
```

#### 2b: Calculate inter-observer error; run the Rmd chunk below.
In this step, we create columns in the recount data to represent difference between original age and recount estimates (0 if there are no differences, and 1 if there is a difference). We then calculate individual and average inter-observer error as described above.

##### Calculate inter-observer error:
```{r}
# Load original count data
save(originals, file = "data/otolith_recounts/originals.Rda")

# Create column in recount data to represent difference between original age and recount estimates (0 if there are no differences, and 1 if there is a difference)
observer_diffs <- originals %>%
  mutate(eddie_joe_diff = as.numeric(ifelse(eddie == joe, "0", "1")),
         eddie_michael_diff = as.numeric(ifelse(eddie == michael, "0", "1")),
         joe_michael_diff = as.numeric(ifelse(joe == michael, "0", "1"))) %>%
  gather(eddie_joe_diff:joe_michael_diff, key = "observers", value = "diff")

# Calcualte intra-observer error for each observer
observer_diffs %>%
  group_by(observers) %>%
  summarize(interobserver_error = mean(diff))

# Calculate average inter-observer error
observer_diffs %>%
  summarize(intra_observer_error = mean(diff))
```

We calculated an average inter-observer error of 0.1494253

## PHASE 2: LINEAR BACK CALCULATION
In this phase of analysis, we conduct linear back-calculation on a subset of relatively high-age fish in our dataset to generate estimates of total length for fish at earlier ages. These estimates are not to be considered independent measurements of age and length, because they are calculated based on the assumption of a direct, one-to-one proportional relationship between an individual's total length and the radii of each annulus in the individual's otolith. Each back-calculated length is therefore an estimate of that individual's length at an earlier age. However, given a large sample size, these estimates can be used to approximate or represent lower age estimates within a population.

### STEP 1: Set "device type" in the package RFishBC (Ogle, 2022) so that the GUI will be readible by MAC OS; run the Rmd chunk below.
In this step, I needed to run a line of code built into the RFishBC package to set the computing device type to "X11", which allows the package's GUI to run on a MAC OS. 

##### Set device type to MAC (X11):
```{r}
RFBCoptions(deviceType = "X11")
```

### STEP 2: Copy raw otolith images into the working directory (`growth_analysis/`).
The RFishBC package requires that raw otolith images being read for back-calculation are placed in the working directory for the Rmd file, which, in this case, is the growth_analysis folder. We therefore *temporarily* copied all raw otolith camera images (`../raw_data/otolith_images/raw/`) into the current working directory.

### STEP 3: Estimate radial measurements of otolith annuli.
In this step, we run the function "digitizeRadii()" from the package RFishBC on each otolith image independently (we list the function for all unique image IDs), which allows interactive radial measurements by drawing radius transects directly on the image. The user is asked to (1) input a unique image ID, (2) draw a linear transect from the nucleus (centroid) to the outer edge of the otolith, and (3) identify each annulus along the transect to match the inferred age of the fish. One output of the function is a data table ("radii", an element of the .rds object) giving the total radius of the otolith and the radii for each individual annulus.

We input the ID given for each otolith (e.g., FBS01, FBS02, etc.). We drew transects from the centroid to the outer edge of the otolith on the same side and just above the sulcus (see Figure S2 in the final manuscript) to standardize radii for each otolith. We identified annuli by placing a reference point on the outermost edge of each annulus. For any otoliths that were cracked (and we could not reliably determine the radius from the nucleus to an otolith edge), cloudy or obscured, or without clearly defined edges, we did not include those samples, and they are indicated within the code chunk.

#### 3a: Estimate radial measurements for Big Sugar Creek samples; run the Rmd chunk below:
In this step, we estimate radial measurements for the Big Sugar Creek samples only.

##### Run linear-back calculation on each image and generate output radius data:
```{r}
# Run linear back-calculation for Big Sugar Creek samples ("FBS")
digitizeRadii("FBS01.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS02.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS03.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS04.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS05.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS06.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS07.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS08.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS09.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS10.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS11.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS12.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS13.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS14.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS15.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS16.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS17.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS18.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS19.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS20.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS21.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS22.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS23.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS24.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS25.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS26.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS27.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS28.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS29.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS30.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS31.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS32.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS33.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS34.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS35.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS36.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS37.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS38.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS39.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS40.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS41.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS42.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS43.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS44.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS45.PNG", edgeIsAnnulus = F)
digitizeRadii("FBS46.PNG", edgeIsAnnulus = F)
```

<b>Big Sugar Creek samples used for back-calculation</b>: <i>N</i> = 46

#### 3b: Estimate radial measurements for Elk River samples; run the Rmd chunk below:
In this step, we estimate radial measurements for the Elk River samples only.

```{r}
# Run linear back-calculation for Elk River samples ("FER")
digitizeRadii("FER01.PNG", edgeIsAnnulus = F)
digitizeRadii("FER02.PNG", edgeIsAnnulus = F)
digitizeRadii("FER03.PNG", edgeIsAnnulus = F)
digitizeRadii("FER04.PNG", edgeIsAnnulus = F)
digitizeRadii("FER05.PNG", edgeIsAnnulus = F)
digitizeRadii("FER06.PNG", edgeIsAnnulus = F)
digitizeRadii("FER07.PNG", edgeIsAnnulus = F)
#digitizeRadii("FER08.PNG", edgeIsAnnulus = F) ## Cracked otolith, unable to reliably determine radius from nucleus to edge
digitizeRadii("FER09.PNG", edgeIsAnnulus = F)
digitizeRadii("FER10.PNG", edgeIsAnnulus = F)
digitizeRadii("FER11.PNG", edgeIsAnnulus = F)
digitizeRadii("FER12.PNG", edgeIsAnnulus = F)
digitizeRadii("FER13.PNG", edgeIsAnnulus = F)
digitizeRadii("FER14.PNG", edgeIsAnnulus = F)
digitizeRadii("FER15.PNG", edgeIsAnnulus = F)
digitizeRadii("FER16.PNG", edgeIsAnnulus = F)
digitizeRadii("FER17.PNG", edgeIsAnnulus = F)
digitizeRadii("FER18.PNG", edgeIsAnnulus = F)
digitizeRadii("FER19.PNG", edgeIsAnnulus = F)
digitizeRadii("FER20.PNG", edgeIsAnnulus = F)
digitizeRadii("FER21.PNG", edgeIsAnnulus = F)
digitizeRadii("FER22.PNG", edgeIsAnnulus = F)
digitizeRadii("FER23.PNG", edgeIsAnnulus = F)
digitizeRadii("FER24.PNG", edgeIsAnnulus = F)
digitizeRadii("FER25.PNG", edgeIsAnnulus = F) 
digitizeRadii("FER26.PNG", edgeIsAnnulus = F)
digitizeRadii("FER27.PNG", edgeIsAnnulus = F)
digitizeRadii("FER28.PNG", edgeIsAnnulus = F) 
digitizeRadii("FER29.PNG", edgeIsAnnulus = F)
digitizeRadii("FER30.PNG", edgeIsAnnulus = F) 
digitizeRadii("FER31.PNG", edgeIsAnnulus = F) 
digitizeRadii("FER32.PNG", edgeIsAnnulus = F)
digitizeRadii("FER33.PNG", edgeIsAnnulus = F)
digitizeRadii("FER34.PNG", edgeIsAnnulus = F)
digitizeRadii("FER35.PNG", edgeIsAnnulus = F)
digitizeRadii("FER36.PNG", edgeIsAnnulus = F)
digitizeRadii("FER37.PNG", edgeIsAnnulus = F)
digitizeRadii("FER38.PNG", edgeIsAnnulus = F)
digitizeRadii("FER39.PNG", edgeIsAnnulus = F)
digitizeRadii("FER40.PNG", edgeIsAnnulus = F)
digitizeRadii("FER41.PNG", edgeIsAnnulus = F)
digitizeRadii("FER42.PNG", edgeIsAnnulus = F)
digitizeRadii("FER43.PNG", edgeIsAnnulus = F)
digitizeRadii("FER44.PNG", edgeIsAnnulus = F)
digitizeRadii("FER45.PNG", edgeIsAnnulus = F)
digitizeRadii("FER46.PNG", edgeIsAnnulus = F)
#digitizeRadii("FER47.PNG", edgeIsAnnulus = F) # Cracked otolith, missing sulcus, unable to reliably determine radius from nucleus to edge
digitizeRadii("FER48.PNG", edgeIsAnnulus = F)
digitizeRadii("FER49.PNG", edgeIsAnnulus = F)
digitizeRadii("FER50.PNG", edgeIsAnnulus = F)
digitizeRadii("FER51.PNG", edgeIsAnnulus = F)
digitizeRadii("FER52.PNG", edgeIsAnnulus = F)
digitizeRadii("FER53.PNG", edgeIsAnnulus = F)
digitizeRadii("FER54.PNG", edgeIsAnnulus = F) 
digitizeRadii("FER55.PNG", edgeIsAnnulus = F)
digitizeRadii("FER56.PNG", edgeIsAnnulus = F)
digitizeRadii("FER57.PNG", edgeIsAnnulus = F)
digitizeRadii("FER58.PNG", edgeIsAnnulus = F)
digitizeRadii("FER59.PNG", edgeIsAnnulus = F)
digitizeRadii("FER60.PNG", edgeIsAnnulus = F)
digitizeRadii("FER61.PNG", edgeIsAnnulus = F)
digitizeRadii("FER62.PNG", edgeIsAnnulus = F)
digitizeRadii("FER63.PNG", edgeIsAnnulus = F)
digitizeRadii("FER64.PNG", edgeIsAnnulus = F)
digitizeRadii("FER65.PNG", edgeIsAnnulus = F)
digitizeRadii("FER66.PNG", edgeIsAnnulus = F)
digitizeRadii("FER68.PNG", edgeIsAnnulus = F)
digitizeRadii("FER69.PNG", edgeIsAnnulus = F)
#digitizeRadii("FER70.PNG", edgeIsAnnulus = F) # Poor image quality
digitizeRadii("FER71.PNG", edgeIsAnnulus = F)
```

<b>Elk River samples used for back-calculation</b>: <i>N</i> = 67
<b>Total samples used for back-calculation</b>: <i>N</i> = 113

#### 3c: Remove all copied raw otolith images from the working directory.

#### 3d: Move all .rds files generated from the digitizeRadii() function into a new folder: `data/bc_rds/`

### STEP 4: Compile and clean all radius measurements stored in .rds files
In this step, we wrote a for-loop to extract the "radii" elements from each of the .rds files generated by the digitizeRadii() function used in Step 3 above. All radii data were for each sample were then compiled into a single dataframe ("bc"). We then cleaned, filtered, and merged the bc data with total length data to perform linear back-calculation of length-at-age.

#### 4a: Extract radial measurements for each sample from .rds files and compile into a single data frame for back-calculation

##### Extract radial measurements and compile into single dataframe:
```{r}
# List rds filers
rds <- list.files(paste("data/bc_rds/"),
                  pattern=".rds$")

# Generate data frame of rds file names
rds_files <- data_frame(rds)

# Generate an empty list to store "radii" data frame elements from .rds files
rds_list <- list()

# Run for loop on all .rds files to extract radii data frame and add to the rds_list (defined above)
for(ii in 1:nrow(rds_files)) {
  
  ## paste the readRDS() function so that it calls each .rds file in the rds files data frame
  read_rds <- readRDS(paste("data/bc_rds/", rds_files[ii,"rds"], sep = ""))$radii
  
  ## Fill the empty list with the iterative output of each read_rds object (defined above)
  rds_list[[paste0("element",ii)]] <- read_rds
  
}

# Concatenate all data frame elements in the list using the list.rbind() function from the package "rlist"
bc_raw <- data.frame(list.rbind(rds_list))

# Save raw bc data 
save(bc_raw, file = "data/bc_data/bc_raw.Rda")
```

#### 4b: Clean and filter radial measurement data for downstream back-calculation; run the Rmd chunk below.
In this step, we clean and filter the radial measurement data so that it can be seamlessly merged with the full ancestry dataset (See Step 5).

Data from the compiled rds files include: 

   1. "sample_id": same as in metadata and genotype data (followed by "structure_number"; see Analysis 3, Phase 1, step 1e)
   2. "consensus age": ultimate age estimate based on consensus of three agers, Eddie, Joe, and Michael 
   3. "annulus": each annulus for each otolith
   4. "annulus_radius": radius of each annulus 
   5. "otolith_radius": total radius of the whole otolith

##### Clean and filter, and merge radial measurement data:
```{r}
# Load raw bc data
load("data/bc_data/bc_raw.Rda")

# Omit rownames
rownames(bc_raw) <- NULL

# Omit empty "reading" column
bc_clean <- bc_raw %>%
  select(-c(reading))

# Modify column names to be more sensible
colnames(bc_clean) <- c("sample_id", "consensus_age", "annulus", "annulus_radius", "otolith_radius")

# Here, I added a row for each of the samples we did not do radius measurements for. I included these as individual rows, because without them, the merging procedure in step 5 results in "NA" values for these individuals since they do not have radial measurements and cannot be used for back-calculation.
bc_clean[451,] <- c("FER08", "2", "2", "1.0000000", "1.0000000")
bc_clean[452,] <- c("FER47", "2", "2", "1.0000000", "1.0000000")
bc_clean[453,] <- c("FER70", "2", "2", "1.0000000", "1.0000000")

# Convert characters to factors
bc_clean <- bc_clean %>%
  mutate(sample_id = factor(sample_id)) %>%
  mutate(consensus_age = as.numeric(consensus_age)) %>%
  mutate(annulus = as.numeric(annulus)) %>%
  mutate(annulus_radius = as.numeric(annulus_radius)) %>%
  mutate(otolith_radius = as.numeric(otolith_radius))

# Save clean radius data for donwtream analyses
save(bc_clean, file = "data/bc_data/bc_clean.Rda")
```

### STEP 5: Merge radius data with full ancestry data (Analysis 3) and perform linear back-calculation 
In this step, we merge the annuli radii data generated above with the full ancestry data generated in Analysis 3, and we perform linear back-calculation using the Dahl-Lea direct proportion model with total length. We estimate length-at-age for each individual fish (age of the fish at all earlier ages) based on the assumed proportional relationship between total length of the fish at a given age and the radius of the fish at the corresponding annulus deposition.

#### 5a: Merge radius data with full ancestry data; run the Rmd chunk below.

##### Merge radius data with full ancestry data:
```{r}
# Load in full ancestry data curated in Analysis 3 
load("../03_ancestry_analysis/data/processed_ancestry_data/full_ancestry_data.Rda")

# Load clean bc data
load("data/bc_data/bc_clean.Rda")

# Filter dataset to keep only fish with total length and consensus age data ("sample"; NOT "reference")
full_ancestry_data <- full_ancestry_data %>%
  filter(population == "sample")

# Merge full ancestry data with bc data 
bc_calc <- merge(full_ancestry_data, 
                 bc_clean, 
                 by = c("sample_id", "consensus_age"))

# Perform back-calculation using the Dahl-Lee model
bc_calc <- bc_calc %>%
  mutate(bc_ratio = annulus_radius/otolith_radius) %>%
  mutate(bc_tl = tl_alive*(annulus_radius/otolith_radius))

# Save calculated bc data
save(bc_calc, file = "data/bc_data/bc_calc.Rda")
```

#### 5b: Remove all length data corresponding to an annulus-to-otolith radial ratio of 1.00; run the Rmd chunk below.
In this step, we standardize all total length data such that the consensus age of the fish (determined by estimating the number of annuli deposited on each otolith) corresponds to the radial measurement of the last deposited otolith, rather than the edge of the otolith. For each fish, the margin of the otolith beyond the final annulus represents additional deposition of calcium carbonate over the course of the year; the exact timing of yearly deposition is dependent on the birth date (exact day) of the fish, which may be variable among fish in our sample. Thus, to standardize length-at-age, we only include back-calculated age data corresponding to each annulus, and not to the edge of the otolith. We therefore do not use the observed lengths of fish collected in the field.

From this point further, the column for "consensus_age", which was the age agreed upon for each fish based on the number of annuli present on the otolith, was considered synonymous with the column "annulus", with the highest annulus number for each sample being equivalent to the consensus age. Each lesser annulus number represents earlier ages for each fish, for which total length is back-calculated.

##### Remove fish with annulus-to-otolith radial ratio of 1.00:
```{r}
# Load calculated bc data 
load("data/bc_data/bc_calc.Rda")

# Remove fish with annulus-to-otolith radial ratio of 1.00
full_bc_data <- bc_calc %>%
  filter(bc_ratio != 1.0000000)

## Verify that the three samples not back-calculated ((FER08, FER47, FER70) were removed from the dataset

# Samples in full_bc_data but not in bc_data
full_bc_data %>% 
  filter(!full_bc_data$sample_id %in% bc_data$sample_id)

# Samples in bc_data but not in full_bc_data
bc_data %>% 
  filter(!bc_data$sample_id %in% full_bc_data$sample_id)

# Save full bc data for downstream growth analysis
save(full_bc_data, file = "data/bc_data/full_bc_data.Rda")
```

After this step, three samples (FER08, FER47, FER70) were omitted from analyses, because we were unable to measure radii for back-calculation (see Steps 3-4 above). These samples were not included in any growth models.

<b>Final back-calculation data summary</b>:
<i>N</i><sub>samples</sub> = 337

### STEP 6: Summarize full back-calculation data for the final manuscript; run the Rmd chunk below.
In this step, we summarize the full back-calculated dataset, which includes back-calculated length-at-annulus data points for all annuli for each fish in the dataset. 

##### Summarize full back-calculated dataset.
```{r}
# Load full bc data
load("data/bc_data/full_bc_data.Rda")

# Get total sample size of bc data
full_bc_data %>%
  count()

# Get sample size by river
full_bc_data %>%
  group_by(river) %>%
  count()

# Get sample size by sex
full_bc_data %>%
  group_by(sex) %>%
  count()

# Get sample size by river
full_bc_data %>%
  group_by(ancestry_group) %>%
  count()

# Get sample size for each annulus for the global dataset (number of fish with a length measurement at each annulus)
full_bc_data %>%
  group_by(annulus) %>%
  count()

# Get mean and standard deviation of back-calculated total length for the global dataset
full_bc_data %>%
  group_by(annulus) %>%
  summarize(mean_bctl = mean(bc_tl),
            sd_bctl = sd(bc_tl))

# Get sample size for each annulus for the stream datasets (number of fish with a length measurement at each annulus within each stream)
full_bc_data %>%
  group_by(annulus, river) %>%
  count()

# Get mean and standard deviation of back-calculated total length for each stream dataset
full_bc_data %>%
  group_by(annulus, river) %>%
  summarize(mean_bctl = mean(bc_tl),
            sd_bctl = sd(bc_tl))

# Get sample size for each annulus for the sex datasets (number of fish with a length measurement at each annulus within each sex)
full_bc_data %>%
  group_by(annulus, sex) %>%
  count()

# Get mean and standard deviation of back-calculated total length for each sex dataset
full_bc_data %>%
  group_by(annulus, sex) %>%
  summarize(mean_bctl = mean(bc_tl),
            sd_bctl = sd(bc_tl))

# Get sample size for each annulus for the ancestry group datasets (number of fish with a length measurement at each annulus within each ancestry group)
full_bc_data %>%
  group_by(annulus, ancestry_group) %>%
  count()

# Get mean and standard deviation of back-calculated total length for each sex dataset
full_bc_data %>%
  group_by(annulus, ancestry_group) %>%
  summarize(mean_bctl = mean(bc_tl),
            sd_bctl = sd(bc_tl))

```

<b>Summary of back-calculated length-at-age sample sizes</b>:

<b>Total sample size</b>: 337

<b><i>By river</i></b>:
<b>Big Sugar Creek</b>: 149
<b>Elk River</b>: 188

<b><i>By sex</i></b>:
<b>Male</b>: 183
<b>Female</b>: 154

<b><i>By ancestry group</i></b>:
<b>NB</b>: 134
<b>SMB</b>: 44
<b>ADM</b>: 159

### ----------------------- END OF PHASE 1: LINEAR BACK-CALCULATION  ----------------------- ###

## PHASE 2: VON BERTALANFFY GROWTH ANALYSIS
In this phase of the analysis, we use a Bayesian hierarchical framework to paramaterize the von Bertalanffy growth model using back-calculated total length and consensus age of samples in the Elk River and Big Sugar Creek to assess the contribution of non-native SMB ancestry to growth. We estimate the linear relationship between population-level growth parameters of the von Bertalanffy model (maximum theoretical total length-at-age, the Brody growth coefficient, and theoretical age at length-0) and ancestry proportion by quantifying average deviations from the global parameters due to SMB vs. NB ancestry, and we account for any potential differences in growth due to sex (male or female) or stream of origin (Big Sugar Creek or Elk River). For all growth models, we include individual ID as a random effect to account for individual variation in linear back-calculation estimates.

### STEP 1: Von bertalanffy growth analysis using back-calculated data.
In this step, we gather format all back-calculated length-at-age data generated in the back-calculation steps in Phase 1 (see above), including factors for stream population (Big Sugar Creek or Elk River) and sex (male or female). These data are then used as input for Bayesian hierarchical analysis. 

#### 1a: Prepare data for Bayesian hierarhical analysis; run the Rmd code below.

##### Load and prepare data for growth analysis:
```{r}
# Load full back-calculated data
load('data/bc_data/full_bc_data.rda')

# Set rstan parameters
rstan_options(threads_per_chain = 1)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores()-1)

# Generate variables and match names to model 
full_bc_data <- full_bc_data %>%
  mutate(river_code = factor(river_code),
         river_code = ifelse(river_code == 3, 2, river_code),
         sex = as.numeric(factor(sex)))

age <- full_bc_data$annulus
length <- full_bc_data$bc_tl
group <- as.numeric(as.factor(full_bc_data$ancestry_group)) 
sample_id <- as.numeric(as.factor(as.character(full_bc_data$sample_id)))
Nind <- length(unique(sample_id))

# Set up model matrix (sex/river) where nrow = number of ind
model_matrix <- full_bc_data %>%
  group_by(sample_id) %>%
  slice(n()) %>%
  select(sample_id, smb, river_code, sex) %>%
  mutate(river_code = factor(river_code),
         sex = factor(sex)) %>%
  arrange(sample_id)

# Define data for model
bc_model_data_test = list(Nobs = length(length),
                     Nages = 15,
                     length = length,
                     age = age,
                     Zero = rep(0, 3),
                     
                     #Priors
                     eta_scale_prior = 0.5, 
                     cholesky_prior = 3,
                     beta_scale = 0.5,
                     
                     Nind = Nind,
                     Ncoef = 2,
                     X = model.matrix(~ sex + river_code, model_matrix)[,2:3],
                     Xhat = matrix(c(0,0,1,0,0,1,1,1), nrow = 4, ncol = 2, byrow = TRUE),
                     q = model_matrix$smb,
                     id = sample.id)

# Save data for back-calculated growth model
save(bc_model_data_test, file = "data/growth_model_data/bc_model_data_test.Rda")
```

#### 1b: Run von Bertalanffy model for back-calculated length at age; run the Rmd chunk below.
In this step, we use a Bayesian hierarchical framework to fit a von Bertalanffy curve to back-calculated length-at-age data and account for SMB ancestry, sex, and stream of origin to assess the effect of SMB ancestry on growth parameters. 

##### Fit von Bertalanffy model:
```{r}
# Load data for back-calculated growth model
load("data/growth_model_data/bc_model_data.Rda")

# Set MCMC specifications
control = list(adapt_delta = 0.999, 
               stepsize = 0.001, 
               max_treedepth = 18)
warmup = 6000       
thin = 2
iter = 6000    

# Run back-calculated growth model
bc_model_fit <- stan(file = "code/bc_model.stan",
                     data = bc_model_data,    
                     chains = 4,            
                     warmup = warmup,      
                     thin = thin,
                     iter = iter * thin + warmup,     
                     cores = 4,            
                     control = control)

# Save back-calculation growth model fit output for downstream analyses
save(bc_model_fit, file = "data/growth_model_data/bc_model_fit.Rda")
```

#### 1c: Summarize and plot model output from von Bertalanffy growth analysis with back-calculated data.
In this step, we analyze and plot output results from the generalized linear model of the condition and ancestry proportion.

##### 1c.1. Run diagnostics on model fit; run the Rmd chunk below:

##### Model diagnostics:
```{r}
# Load back-calculated model fit output
load("data/growth_model_data/bc_model_fit.Rda")

# Visually inspect chains
traceplot(bc_model_fit)

# Extract summary data for model fit  
sampler_params <- get_sampler_params(bc_model_fit, inc_warmup = TRUE)

# Summarize model fit
summary(do.call(rbind, sampler_params), digits = 2)

# Convergence diagnostics ----
#https://mc-stan.org/bayesplot/articles/visual-mcmc-diagnostics.html

#Posterior ll
lp_cp <- log_posterior(bc_model_fit)
head(lp_cp)

#Accepted prob
np_cp <- nuts_params(bc_model_fit)
head(np_cp)

# Look at par vs divergence
color_scheme_set("darkgray")
posterior_cp <- as.array(bc_model_fit)
mcmc_parcoord(posterior_cp, np = np_cp)

#Look at ll vs acceptance
color_scheme_set("red")
mcmc_nuts_divergence(np_cp, lp_cp)

# Print and plot MCMC ----
print(bc_model_fit, pars=c("mu_linf", "mu_k", "mu_t0", "beta_linf", "beta_k", "beta_t0", "linf_lineage", "k_lineage", "t0_lineage"), probs=c(.1,.5,.9)) # None of the betas are sig
traceplot(bc_model_fit, pars = c("mu_linf", "mu_k", "mu_t0", "sigma"), inc_warmup = FALSE, nrow = 2)
traceplot(bc_model_fit, pars = c("beta_linf", "beta_k", "beta_t0"), inc_warmup = FALSE, nrow = 2)
traceplot(bc_model_fit, pars = c("Lcorr", "sigma_group"), inc_warmup = FALSE, nrow = 2)
traceplot(bc_model_fit, pars = c("Lcorr", "sigma_ind"), inc_warmup = FALSE, nrow = 2)

pairs(bc_model_fit, pars = c("mu_linf", "mu_k", "mu_t0", "lp__"), las = 1)
pairs(bc_model_fit, pars = c("linf_lineage", "k_lineage", "t0_lineage", "lp__"), las = 1)
pairs(bc_model_fit, pars = c("beta_linf", "beta_k", "beta_t0", "lp__"), las = 1)
pairs(bc_model_fit, pars = c("sigma_group", "Lcorr", "lp__"), las = 1)
pairs(bc_model_fit, pars = c("sigma_ind", "Lcorr", "lp__"), las = 1)

# BFMI low
pairs_stan <- function(chain, stan_model, pars) {
energy <- as.matrix(sapply(get_sampler_params(stan_model, inc_warmup = F), 
                           function(x) x[,"energy__"]))
pars <- extract(stan_model, pars = pars, permuted = F)
df <- data.frame(energy[,chain], pars[,chain,])
names(df)[1] <- "energy"

GGally::ggpairs(df, title = paste0("Chain", chain), 
                lower = list(continuous = GGally::wrap("points", alpha = 0.2)))                    
 }
 
pairs_stan(1, bc_model_fit, pars = c("mu_linf", "mu_k", "mu_t0", "lp__"))
pairs_stan(1, bc_model_fit, pars = c("linf_lineage", "k_lineage", "t0_lineage", "lp__"))
pairs_stan(1, bc_model_fit, pars = c("beta_linf", "beta_k", "beta_t0", "lp__"))
pairs_stan(1, bc_model_fit, pars = c("Lcorr", "lp__"))

check_energy(bc_model_fit)

# Rhat for chain convergence
rhats <- rhat(bc_model_fit)
color_scheme_set("brightblue") # see help("color_scheme_set")
mcmc_rhat(rhats)
rhats <- data.frame(Parm = names(rhats), Rhat = rhats)

# Plot prior and posterior density distributions with custom code
source("code/plot_density.R")
plot_density(bc_model_fit, file_name = "growth_analysis/figures/bc_density.pdf", probs = c(0.01, 0.99))
```

##### 1c.2. Summarize mean and 95 credible intervals for all model coefficients; run the Rmd chunk below:

##### Summarize back-calculated growth model fit model output:
```{r}
# Load back-calculated model fit output
load('data/growth_model_data/bc_model_fit.Rda')

# Convert model fit data to dataframe
bc_model_fit <- as.data.frame(bc_model_fit)

# select columns with parameter estimates to summarize for analysis, and calculate posterior differences for ancestry-specific parameters
bc_fixed <- bc_model_fit %>%
  select(mu_linf, mu_k, mu_t0, "linf_lineage[1]", "linf_lineage[2]", "k_lineage[1]", "k_lineage[2]", "t0_lineage[1]", "t0_lineage[2]", "beta_linf[1]", "beta_linf[2]", "beta_k[1]", "beta_k[2]", "beta_t0[1]", "beta_t0[2]") %>%
  mutate(linf_diff = `linf_lineage[1]` - `linf_lineage[2]`,
         k_diff = `k_lineage[1]` - `k_lineage[2]`,
         t0_diff = `t0_lineage[1]` - `t0_lineage[2]`)

# Gather parameters and estimates at each iteration so that there are only two columns
bc_fixed <- bc_fixed %>%
  gather(mu_linf:t0_diff, key = "parameter", value = "estimate") %>%
  mutate(parameter = factor(parameter))

# Summarize parameter estimates and 95% credible intervals
bc_fixed %>%
  group_by(parameter) %>%
  summarize(mean = mean(estimate),
            sd = sd(estimate),
            q2.5 = quantile(estimate, probs = 0.025),
            q5 = quantile(estimate, probs = 0.05), 
            q50 = quantile(estimate, probs = 0.50),
            q95 = quantile(estimate, probs = 0.95),
            q97.5 = quantile(estimate, probs = 0.975))
```

##### 1c.3. Plot 95% credible intervals for posterior differences of L∞, k, and a0 parameters; run the Rmd chunk below.

##### Plot posterior differences: `figures/bc_p_diffs.pdf`
```{r}
# Load back-calculated model fit output
load('data/growth_model_data/bc_model_fit.Rda')

# Convert model fit data to dataframe
bc_model_fit <- as.data.frame(bc_model_fit)

# select columns with parameter estimates to summarize for analysis, and calculate posterior differences for ancestry-specific parameters
bc_fixed <- bc_model_fit %>%
  select(mu_linf, mu_k, mu_t0, "linf_lineage[1]", "linf_lineage[2]", "k_lineage[1]", "k_lineage[2]", "t0_lineage[1]", "t0_lineage[2]", "beta_linf[1]", "beta_linf[2]", "beta_k[1]", "beta_k[2]", "beta_t0[1]", "beta_t0[2]") %>%
  mutate(linf_diff = `linf_lineage[1]` - `linf_lineage[2]`,
         k_diff = `k_lineage[1]` - `k_lineage[2]`,
         t0_diff = `t0_lineage[1]` - `t0_lineage[2]`)

# Gather parameters and estimates at each iteration so that there are only two columns
bc_fixed <- bc_fixed %>%
  gather(mu_linf:t0_diff, key = "parameter", value = "estimate") %>%
  mutate(parameter = factor(parameter))

# Select only linf difference parameter for plotting
linf_p_diffs <- bc_fixed %>%
  filter(parameter == "linf_diff")

# Select only k difference parameter for plotting
k_p_diffs <- bc_fixed %>%
  filter(parameter == "k_diff")

# Select only t0 difference parameter for plotting
t0_p_diffs <- bc_fixed %>%
  filter(parameter == "t0_diff")

# Get posterior difference parameter plots
linf <- ggplot(linf_p_diffs, aes(x = parameter, y = estimate)) +
  geom_boxplot(fill = "grey") +
  theme_set(theme_cowplot(12)) +
  labs(x = "Parameter", y = "Estimate") + 
  geom_hline(yintercept = 0, size = 1, linetype = "longdash", color = "red") +
  theme(axis.text = element_text(size = 15)) +
  theme(axis.title = element_blank()) + 
  theme(axis.text.x = element_blank()) +
  theme(panel.border = element_rect(colour = "black", fill = NA)) +
  theme(plot.margin = margin(10,10,10,10))

# Get posterior difference parameter plots
k <- ggplot(k_p_diffs, aes(x = parameter, y = estimate)) +
  geom_boxplot(fill = "grey") +
  theme_set(theme_cowplot(12)) +
  labs(x = "Parameter", y = "Estimate") + 
  geom_hline(yintercept = 0, size = 1, linetype = "longdash", color = "red") +
  theme(axis.text = element_text(size = 15)) +
  theme(axis.title = element_blank()) + 
  theme(axis.text.x = element_blank()) +
  theme(panel.border = element_rect(colour = "black", fill = NA)) +
  theme(plot.margin = margin(10,10,10,10))

# Get posterior difference parameter plots
t0 <- ggplot(t0_p_diffs, aes(x = parameter, y = estimate)) +
  geom_boxplot(fill = "grey") +
  theme_set(theme_cowplot(12)) +
  labs(x = "Parameter", y = "Estimate") + 
  geom_hline(yintercept = 0, size = 1, linetype = "longdash", color = "red") +
  theme(axis.text = element_text(size = 15)) +
  theme(axis.title = element_blank()) + 
  theme(axis.text.x = element_blank()) +
  theme(panel.border = element_rect(colour = "black", fill = NA)) +
  theme(plot.margin = margin(10,10,10,10))

# Plot posterior difference 95% CIs
pdf("figures/bc_p_diffs.pdf", width = 9, height = 5)

plot_grid(linf,
          k,
          t0,
          nrow = 1,
          ncol = 3)

dev.off()
```

##### 1c.4. Plot 95% credible intervals for beta coefficient posterior densities of L∞, k, and a0 parameters for sex and stream; run the Rmd chunk below.

##### Plot posterior differences: 1) `figures/bc_sex_betas.pdf`, 2) `figures/bc_stream_betas.pdf`
```{r}
# Load back-calculated model fit output
load('data/growth_model_data/bc_model_fit.Rda')

# Convert model fit data to dataframe
bc_model_fit <- as.data.frame(bc_model_fit)

# select columns with parameter estimates to summarize for analysis, and calculate posterior differences for ancestry-specific parameters
bc_fixed <- bc_model_fit %>%
  select(mu_linf, mu_k, mu_t0, "linf_lineage[1]", "linf_lineage[2]", "k_lineage[1]", "k_lineage[2]", "t0_lineage[1]", "t0_lineage[2]", "beta_linf[1]", "beta_linf[2]", "beta_k[1]", "beta_k[2]", "beta_t0[1]", "beta_t0[2]") %>%
  mutate(linf_diff = `linf_lineage[1]` - `linf_lineage[2]`,
         k_diff = `k_lineage[1]` - `k_lineage[2]`,
         t0_diff = `t0_lineage[1]` - `t0_lineage[2]`)

# Gather parameters and estimates at each iteration so that there are only two columns
bc_fixed <- bc_fixed %>%
  gather(mu_linf:t0_diff, key = "parameter", value = "estimate") %>%
  mutate(parameter = factor(parameter))

# Select only posterior densities for stream- and sex-specific fixed effects
stream_sex_betas <- bc_fixed %>%
  filter(parameter == "beta_linf[1]" |
           parameter == "beta_linf[2]" |
           parameter == "beta_k[1]" |
           parameter == "beta_k[2]" |
           parameter == "beta_t0[1]" |
           parameter == "beta_t0[2]")

# Add column in beta table to describe parameter type (linf, k, and t0) for facet wrapping in plot
stream_sex_betas$variable <- factor(c(rep("Sex", times = 24000), 
                                      rep("Stream", times = 24000), 
                                      rep("Sex", times = 24000), 
                                      rep("Stream", times = 24000), 
                                      rep("Sex", times = 24000), 
                                      rep("Stream", times = 24000)))

# Get only betas for sex
sex_betas <- stream_sex_betas %>%
  filter(variable == "Sex")

# Get only betas for stream 
stream_betas <- stream_sex_betas %>%
  filter(variable == "Stream")

# Put parameters in desired order to show up on graph (linf, then k, then t0)
sex_betas$parameter <- factor(sex_betas$parameter, levels = c("beta_linf[1]", "beta_k[1]", "beta_t0[1]"))

# Put parameters in desired order to show up on graph (linf, then k, then t0)
stream_betas$parameter <- factor(stream_betas$parameter, levels = c("beta_linf[2]", "beta_k[2]", "beta_t0[2]"))

# Plot sex beta coefficient 95% CIs
pdf("figures/bc_sex_betas.pdf", width = 7, height = 5)

ggplot(sex_betas, aes(x = parameter, y = estimate)) +
  geom_boxplot(fill = "grey") +
  theme_set(theme_cowplot(12)) +
  labs(x = "Parameter", y = "Estimate") + 
  geom_hline(yintercept = 0, size = 1, linetype = "longdash", color = "red") +
  theme(axis.text = element_text(size = 15)) +
  theme(axis.title = element_text(size = 15)) + 
  theme(axis.text.x = element_blank()) +
  theme(panel.border = element_rect(colour = "black", fill = NA)) +
  theme(plot.margin = margin(10,10,10,10))

dev.off()

# Plot sex beta coefficient 95% CIs
pdf("figures/bc_stream_betas.pdf", width = 7, height = 5)

ggplot(stream_betas, aes(x = parameter, y = estimate)) +
  geom_boxplot(fill = "grey") +
  theme_set(theme_cowplot(12)) +
  labs(x = "Parameter", y = "Estimate") + 
  geom_hline(yintercept = 0, size = 1, linetype = "longdash", color = "red") +
  theme(axis.text = element_text(size = 15)) +
  theme(axis.title = element_text(size = 15)) + 
  theme(axis.text.x = element_blank()) +
  theme(panel.border = element_rect(colour = "black", fill = NA)) +
  theme(plot.margin = margin(10,10,10,10))

dev.off()
```

##### 1c.5. Plot predicted length-at-age using calculated parameter values; run the Rmd chunk below.

##### Plot back-calculated length-at-age prediction: `figures/bc_predict.pdf`
```{r}
# Load back-calculated model fit output
load('data/growth_model_data/bc_model_fit.Rda')

# Load data for back-calculated growth model
load("data/growth_model_data/bc_model_data.Rda")

# Load bc data
load("data/bc_data/full_bc_data.Rda")

# Convert model fit data to dataframe
bc_model_fit <- as.data.frame(bc_model_fit)

# Get sequence of ages
ages <- seq(1, 15, 1)

# Generate empty matrix to hold predicted length values up to 15 annuli for female SMB from Big Sugar Creek
f_bs_smb_predicted_length <- matrix(NA,
                                    length(bc_model_fit$mu_linf), 
                                    length(ages)) 

# Generate empty matrix to hold predicted length values up to 15 annuli for female NB from Big Sugar Creek
f_bs_nb_predicted_length <- matrix(NA,
                                   length(bc_model_fit$mu_linf), 
                                   length(ages)) 

# Generate empty matrix to hold predicted length values up to 15 annuli for female SMB from Elk River
f_e_smb_predicted_length <- matrix(NA, 
                                   length(bc_model_fit$mu_linf), 
                                   length(ages)) 

# Generate empty matrix to hold predicted length values up to 15 annuli for female NB from Elk River
f_e_nb_predicted_length <- matrix(NA, 
                                  length(bc_model_fit$mu_linf),
                                  length(ages)) 

# Generate empty matrix to hold predicted length values up to 15 annuli for male SMB from Big Sugar Creek
m_bs_smb_predicted_length <- matrix(NA,
                                    length(bc_model_fit$mu_linf), 
                                    length(ages)) 

# Generate empty matrix to hold predicted length values up to 15 annuli for male NB from Big Sugar Creek
m_bs_nb_predicted_length <- matrix(NA, 
                                   length(bc_model_fit$mu_linf), 
                                   length(ages)) 

# Generate empty matrix to hold predicted length values up to 15 annuli for male SMB from Elk River
m_e_smb_predicted_length <- matrix(NA, 
                                   length(bc_model_fit$mu_linf), 
                                   length(ages)) 

# Generate empty matrix to hold predicted length values up to 15 annuli for male NB from Elk River
m_e_nb_predicted_length <- matrix(NA, 
                                  length(bc_model_fit$mu_linf), 
                                  length(ages)) 

# Fill empty matrix for female SMB from Big Sugar Creek
for (i in 1:length(ages)) { # fill empty matrix with predicted values using the model
   f_bs_smb_predicted_length[,i] = bc_model_fit$`pred_linf[1]` * exp(bc_model_fit$eta_smb_linf) * (1 - exp(-bc_model_fit$`pred_k[1]` * exp(bc_model_fit$eta_smb_k) * (i - bc_model_fit$`pred_t0[1]` - bc_model_fit$eta_smb_t0)))

}

# Fill empty matrix for female NB from Big Sugar Creek
for (i in 1:length(ages)) { # fill empty matrix with predicted values using the model
   f_bs_nb_predicted_length[,i] = bc_model_fit$`pred_linf[1]` * exp(bc_model_fit$eta_n_linf) * (1 - exp(-bc_model_fit$`pred_k[1]` * exp(bc_model_fit$eta_n_k) * (i - bc_model_fit$`pred_t0[1]` - bc_model_fit$eta_n_t0)))

}

# Fill empty matrix for female SMB from Elk River
for (i in 1:length(ages)) { # fill empty matrix with predicted values using the model
   f_e_smb_predicted_length[,i] = bc_model_fit$`pred_linf[3]` * exp(bc_model_fit$eta_smb_linf) * (1 - exp(-bc_model_fit$`pred_k[3]` * exp(bc_model_fit$eta_smb_k) * (i - bc_model_fit$`pred_t0[3]` - bc_model_fit$eta_smb_t0)))

}

# Fill empty matrix for female NB from Elk River
for (i in 1:length(ages)) { # fill empty matrix with predicted values using the model
   f_e_nb_predicted_length[,i] = bc_model_fit$`pred_linf[3]` * exp(bc_model_fit$eta_n_linf) * (1 - exp(-bc_model_fit$`pred_k[3]` * exp(bc_model_fit$eta_n_k) * (i - bc_model_fit$`pred_t0[3]` - bc_model_fit$eta_n_t0)))

}

# Fill empty matrix for male SMB from Big Sugar Creek
for (i in 1:length(ages)) { # fill empty matrix with predicted values using the model
   m_bs_smb_predicted_length[,i] = bc_model_fit$`pred_linf[2]` * exp(bc_model_fit$eta_smb_linf) * (1 - exp(-bc_model_fit$`pred_k[2]` * exp(bc_model_fit$eta_smb_k) * (i - bc_model_fit$`pred_t0[2]` - bc_model_fit$eta_smb_t0)))

}

# Fill empty matrix for male NB from Big Sugar Creek
for (i in 1:length(ages)) { # fill empty matrix with predicted values using the model
   m_bs_nb_predicted_length[,i] = bc_model_fit$`pred_linf[2]` * exp(bc_model_fit$eta_n_linf) * (1 - exp(-bc_model_fit$`pred_k[2]` * exp(bc_model_fit$eta_n_k) * (i - bc_model_fit$`pred_t0[2]` - bc_model_fit$eta_n_t0)))

}

# Fill empty matrix for male SMB from Elk River
for (i in 1:length(ages)) { # fill empty matrix with predicted values using the model
   m_e_smb_predicted_length[,i] = bc_model_fit$`pred_linf[4]` * exp(bc_model_fit$eta_smb_linf) * (1 - exp(-bc_model_fit$`pred_k[4]` * exp(bc_model_fit$eta_smb_k) * (i - bc_model_fit$`pred_t0[4]` - bc_model_fit$eta_smb_t0)))

}

# Fill empty matrix for male NB from Elk River
for (i in 1:length(ages)) { # fill empty matrix with predicted values using the model
   m_e_nb_predicted_length[,i] = bc_model_fit$`pred_linf[4]` * exp(bc_model_fit$eta_n_linf) * (1 - exp(-bc_model_fit$`pred_k[4]`* exp(bc_model_fit$eta_n_k) * (i - bc_model_fit$`pred_t0[4]` - bc_model_fit$eta_n_t0)))

}

# Get numeric vectors to hold means and credible interval estimates from predictions
f_bs_smb_mean_length <- f_bs_smb_uci_length <- f_bs_smb_lci_length <- numeric()
f_bs_nb_mean_length <- f_bs_nb_uci_length <- f_bs_nb_lci_length <- numeric()
f_e_smb_mean_length <- f_e_smb_uci_length <- f_e_smb_lci_length <- numeric()
f_e_nb_mean_length <- f_e_nb_uci_length <- f_e_nb_lci_length <- numeric()
m_bs_smb_mean_length <- m_bs_smb_uci_length <- m_bs_smb_lci_length <- numeric()
m_bs_nb_mean_length <- m_bs_nb_uci_length <- m_bs_nb_lci_length <- numeric()
m_e_smb_mean_length <- m_e_smb_uci_length <- m_e_smb_lci_length <- numeric()
m_e_nb_mean_length <- m_e_nb_uci_length <- m_e_nb_lci_length <- numeric()

# Predict mean and confidence intervals around trendline for female SMB from Big Sugar Creek
for (i in 1:length(ages)){
  f_bs_smb_mean_length[i] <- mean(f_bs_smb_predicted_length[,i]) 
  f_bs_smb_uci_length[i] <- quantile(f_bs_smb_predicted_length[,i], probs=0.975)
  f_bs_smb_lci_length[i] <- quantile(f_bs_smb_predicted_length[,i], probs=0.025)
}

# Generate dataframes for each vector
f_bs_smb_mean_length <- as.data.frame(f_bs_smb_mean_length)
f_bs_smb_uci_length <- as.data.frame(f_bs_smb_uci_length)
f_bs_smb_lci_length <- as.data.frame(f_bs_smb_lci_length)

# Change column names
colnames(f_bs_smb_mean_length) <- c("length")
colnames(f_bs_smb_uci_length) <- c("uci")
colnames(f_bs_smb_lci_length) <- c("lci")

# Add additional descriptor columns for ancestry, sex, and stream
f_bs_smb_lci_length$ancestry <- factor(rep("SMB", times = 15))
f_bs_smb_lci_length$sex <- factor(rep("Female", times = 15))
f_bs_smb_lci_length$stream <- factor(rep("Big Sugar Creek", times = 15))

# Bind mean, uci, and lci columns together
f_bs_smb <- cbind(ages,
                  f_bs_smb_mean_length,
                  f_bs_smb_uci_length,
                  f_bs_smb_lci_length)

# Predict mean and confidence intervals around trendline for female NB from Big Sugar Creek
for (i in 1:length(ages)){
  f_bs_nb_mean_length[i] <- mean(f_bs_nb_predicted_length[,i]) 
  f_bs_nb_uci_length[i] <- quantile(f_bs_nb_predicted_length[,i], probs=0.975)
  f_bs_nb_lci_length[i] <- quantile(f_bs_nb_predicted_length[,i], probs=0.025)
}

# Generate dataframes for each vector
f_bs_nb_mean_length <- as.data.frame(f_bs_nb_mean_length)
f_bs_nb_uci_length <- as.data.frame(f_bs_nb_uci_length)
f_bs_nb_lci_length <- as.data.frame(f_bs_nb_lci_length)

# Change column names
colnames(f_bs_nb_mean_length) <- c("length")
colnames(f_bs_nb_uci_length) <- c("uci")
colnames(f_bs_nb_lci_length) <- c("lci")

# Add additional descriptor columns for ancestry, sex, and stream
f_bs_nb_lci_length$ancestry <- factor(rep("NB", times = 15))
f_bs_nb_lci_length$sex <- factor(rep("Female", times = 15))
f_bs_nb_lci_length$stream <- factor(rep("Big Sugar Creek", times = 15))

# Bind mean, uci, and lci columns together
f_bs_nb <- cbind(ages,
                 f_bs_nb_mean_length,
                 f_bs_nb_uci_length,
                 f_bs_nb_lci_length)

# Predict mean and confidence intervals around trendline for female SMB from Elk River
for (i in 1:length(ages)){
  f_e_smb_mean_length[i] <- mean(f_e_smb_predicted_length[,i]) 
  f_e_smb_uci_length[i] <- quantile(f_e_smb_predicted_length[,i], probs=0.975)
  f_e_smb_lci_length[i] <- quantile(f_e_smb_predicted_length[,i], probs=0.025)
}

# Generate dataframes for each vector
f_e_smb_mean_length <- as.data.frame(f_e_smb_mean_length)
f_e_smb_uci_length <- as.data.frame(f_e_smb_uci_length)
f_e_smb_lci_length <- as.data.frame(f_e_smb_lci_length)

# Change column names
colnames(f_e_smb_mean_length) <- c("length")
colnames(f_e_smb_uci_length) <- c("uci")
colnames(f_e_smb_lci_length) <- c("lci")

# Add additional descriptor columns for ancestry, sex, and stream
f_e_smb_lci_length$ancestry <- factor(rep("SMB", times = 15))
f_e_smb_lci_length$sex <- factor(rep("Female", times = 15))
f_e_smb_lci_length$stream <- factor(rep("Elk River", times = 15))

# Bind mean, uci, and lci columns together
f_e_smb <- cbind(ages,
                 f_e_smb_mean_length,
                 f_e_smb_uci_length,
                 f_e_smb_lci_length)

# Predict mean and confidence intervals around trendline for female NB from Elk River
for (i in 1:length(ages)){
  f_e_nb_mean_length[i] <- mean(f_e_nb_predicted_length[,i]) 
  f_e_nb_uci_length[i] <- quantile(f_e_nb_predicted_length[,i], probs=0.975)
  f_e_nb_lci_length[i] <- quantile(f_e_nb_predicted_length[,i], probs=0.025)
}

# Generate dataframes for each vector
f_e_nb_mean_length <- as.data.frame(f_e_nb_mean_length)
f_e_nb_uci_length <- as.data.frame(f_e_nb_uci_length)
f_e_nb_lci_length <- as.data.frame(f_e_nb_lci_length)

# Change column names
colnames(f_e_nb_mean_length) <- c("length")
colnames(f_e_nb_uci_length) <- c("uci")
colnames(f_e_nb_lci_length) <- c("lci")

# Add additional descriptor columns for ancestry, sex, and stream
f_e_nb_lci_length$ancestry <- factor(rep("NB", times = 15))
f_e_nb_lci_length$sex <- factor(rep("Female", times = 15))
f_e_nb_lci_length$stream <- factor(rep("Elk River", times = 15))

# Bind mean, uci, and lci columns together
f_e_nb <- cbind(ages,
                f_e_nb_mean_length,
                f_e_nb_uci_length,
                f_e_nb_lci_length)

# Predict mean and confidence intervals around trendline for male SMB from Big Sugar Creek
for (i in 1:length(ages)){
  m_bs_smb_mean_length[i] <- mean(m_bs_smb_predicted_length[,i]) 
  m_bs_smb_uci_length[i] <- quantile(m_bs_smb_predicted_length[,i], probs=0.975)
  m_bs_smb_lci_length[i] <- quantile(m_bs_smb_predicted_length[,i], probs=0.025)
}

# Generate dataframes for each vector
m_bs_smb_mean_length <- as.data.frame(m_bs_smb_mean_length)
m_bs_smb_uci_length <- as.data.frame(m_bs_smb_uci_length)
m_bs_smb_lci_length <- as.data.frame(m_bs_smb_lci_length)

# Change column names
colnames(m_bs_smb_mean_length) <- c("length")
colnames(m_bs_smb_uci_length) <- c("uci")
colnames(m_bs_smb_lci_length) <- c("lci")

# Add additional descriptor columns for ancestry, sex, and stream
m_bs_smb_lci_length$ancestry <- factor(rep("SMB", times = 15))
m_bs_smb_lci_length$sex <- factor(rep("Male", times = 15))
m_bs_smb_lci_length$stream <- factor(rep("Big Sugar Creek", times = 15))

# Bind mean, uci, and lci columns together
m_bs_smb <- cbind(ages,
                  m_bs_smb_mean_length,
                  m_bs_smb_uci_length,
                  m_bs_smb_lci_length)

# Predict mean and confidence intervals around trendline for male NB from Big Sugar Creek
for (i in 1:length(ages)){
  m_bs_nb_mean_length[i] <- mean(m_bs_nb_predicted_length[,i]) 
  m_bs_nb_uci_length[i] <- quantile(m_bs_nb_predicted_length[,i], probs=0.975)
  m_bs_nb_lci_length[i] <- quantile(m_bs_nb_predicted_length[,i], probs=0.025)
}

# Generate dataframes for each vector
m_bs_nb_mean_length <- as.data.frame(m_bs_nb_mean_length)
m_bs_nb_uci_length <- as.data.frame(m_bs_nb_uci_length)
m_bs_nb_lci_length <- as.data.frame(m_bs_nb_lci_length)

# Change column names
colnames(m_bs_nb_mean_length) <- c("length")
colnames(m_bs_nb_uci_length) <- c("uci")
colnames(m_bs_nb_lci_length) <- c("lci")

# Add additional descriptor columns for ancestry, sex, and stream
m_bs_nb_lci_length$ancestry <- factor(rep("NB", times = 15))
m_bs_nb_lci_length$sex <- factor(rep("Male", times = 15))
m_bs_nb_lci_length$stream <- factor(rep("Big Sugar Creek", times = 15))

# Bind mean, uci, and lci columns together
m_bs_nb <- cbind(ages,
                 m_bs_nb_mean_length,
                 m_bs_nb_uci_length,
                 m_bs_nb_lci_length)

# Predict mean and confidence intervals around trendline for male SMB from Elk River
for (i in 1:length(ages)){
  m_e_smb_mean_length[i] <- mean(m_e_smb_predicted_length[,i]) 
  m_e_smb_uci_length[i] <- quantile(m_e_smb_predicted_length[,i], probs=0.975)
  m_e_smb_lci_length[i] <- quantile(m_e_smb_predicted_length[,i], probs=0.025)
}

# Generate dataframes for each vector
m_e_smb_mean_length <- as.data.frame(m_e_smb_mean_length)
m_e_smb_uci_length <- as.data.frame(m_e_smb_uci_length)
m_e_smb_lci_length <- as.data.frame(m_e_smb_lci_length)

# Change column names
colnames(m_e_smb_mean_length) <- c("length")
colnames(m_e_smb_uci_length) <- c("uci")
colnames(m_e_smb_lci_length) <- c("lci")

# Add additional descriptor columns for ancestry, sex, and stream
m_e_smb_lci_length$ancestry <- factor(rep("SMB", times = 15))
m_e_smb_lci_length$sex <- factor(rep("Male", times = 15))
m_e_smb_lci_length$stream <- factor(rep("Elk River", times = 15))

# Bind mean, uci, and lci columns together
m_e_smb <- cbind(ages,
                 m_e_smb_mean_length,
                 m_e_smb_uci_length,
                 m_e_smb_lci_length)

# Predict mean and confidence intervals around trendline for male NB from Elk River
for (i in 1:length(ages)){
  m_e_nb_mean_length[i] <- mean(m_e_nb_predicted_length[,i]) 
  m_e_nb_uci_length[i] <- quantile(m_e_nb_predicted_length[,i], probs=0.975)
  m_e_nb_lci_length[i] <- quantile(m_e_nb_predicted_length[,i], probs=0.025)
}

# Generate dataframes for each vector
m_e_nb_mean_length <- as.data.frame(m_e_nb_mean_length)
m_e_nb_uci_length <- as.data.frame(m_e_nb_uci_length)
m_e_nb_lci_length <- as.data.frame(m_e_nb_lci_length)

# Change column names
colnames(m_e_nb_mean_length) <- c("length")
colnames(m_e_nb_uci_length) <- c("uci")
colnames(m_e_nb_lci_length) <- c("lci")

# Add additional descriptor columns for ancestry, sex, and stream
m_e_nb_lci_length$ancestry <- factor(rep("NB", times = 15))
m_e_nb_lci_length$sex <- factor(rep("Male", times = 15))
m_e_nb_lci_length$stream <- factor(rep("Elk River", times = 15))

# Bind mean, uci, and lci columns together
m_e_nb <- cbind(ages,
                m_e_nb_mean_length,
                m_e_nb_uci_length,
                m_e_nb_lci_length)
  
# Bind all data frames together by row
bc_predict <- rbind(f_bs_smb,
                    f_bs_nb,
                    f_e_smb,
                    f_e_nb,
                    m_bs_smb,
                    m_bs_nb,
                    m_e_smb,
                    m_e_nb)

# Get dataframe for females in Big Sugar Creek
f_bs <- bc_predict %>%
  filter(sex == "Female" & stream == "Big Sugar Creek")

# Get dataframe for males in Big Sugar Creek
m_bs <- bc_predict %>%
  filter(sex == "Male" & stream == "Big Sugar Creek")

# Get dataframe for females in Elk River
f_e <- bc_predict %>%
  filter(sex == "Female" & stream == "Elk River")

# Get dataframe for males in Elk River
m_e <- bc_predict %>%
  filter(sex == "Male" & stream == "Elk River")

# Get raw data for females in Big Sugar Creek
bc_f_bs <- full_bc_data %>%
  filter(sex == "Female" & river == "Big_Sugar")

# Get raw data for males in Big Sugar Creek
bc_m_bs <- full_bc_data %>%
  filter(sex == "Male" & river == "Big_Sugar")

# Get raw data for females in Elk River
bc_f_e <- full_bc_data %>%
  filter(sex == "Female" & river == "Elk_River")

# Get raw data for males in Elk River
bc_m_e <- full_bc_data %>%
  filter(sex == "Male" & river == "Elk_River")


# Plot females in big sugar creek
f_bs_plot <- ggplot() + 
  geom_ribbon(data = f_bs, aes(x = ages, ymin = lci, ymax = uci, fill = ancestry, alpha = 0.01), show.legend = T) +
  geom_point(data = bc_f_bs, aes(x = annulus, y = bc_tl), position = position_jitter(width = 0.3), fill = "grey", show.legend = F, size = 3, pch = 21, alpha = 0.6) + 
  geom_line(data = f_bs, aes(x = ages, y = length, color = ancestry), size = 1, show.legend = F) +
  theme_set(theme_cowplot(12)) +
  scale_color_manual(values = c("deeppink2","deepskyblue")) +
  scale_fill_manual(values = c("grey","grey")) +
  scale_x_continuous(name = "Annulus (years)", expand = c(0,0), breaks = seq(1, 15, 1)) +
  scale_y_continuous(name = "Back-calculated total length (mm)", limits = c(0,550), breaks = seq(0, 550, 50)) +
  theme(axis.title = element_text(size = 15)) + 
  theme(axis.text = element_text(size = 15)) +
  theme(panel.border = element_rect(colour = "black", fill = NA)) +
  theme(plot.margin = margin(15,15,15,15))

# Plot males in big sugar creek
m_bs_plot <- ggplot() + 
  geom_ribbon(data = m_bs, aes(x = ages, ymin = lci, ymax = uci, fill = ancestry, alpha = 0.01), show.legend = F) +
  geom_point(data = bc_m_bs, aes(x = annulus, y = bc_tl), position = position_jitter(width = 0.3), fill = "grey", show.legend = F, size = 3, pch = 21, alpha = 0.6) + 
  geom_line(data = m_bs, aes(x = ages, y = length, color = ancestry), size = 1, show.legend = F) +
  theme_set(theme_cowplot(12)) +
  scale_color_manual(values = c("deeppink2","deepskyblue")) +
  scale_fill_manual(values = c("grey","grey")) +
  scale_x_continuous(name = "Annulus (years)", expand = c(0,0), breaks = seq(1, 15, 1)) +
  scale_y_continuous(name = "Back-calculated total length (mm)", limits = c(0,550), breaks = seq(0, 550, 50)) +
  theme(axis.title = element_text(size = 15)) + 
  theme(axis.text = element_text(size = 15)) +
  theme(panel.border = element_rect(colour = "black", fill = NA)) +
  theme(plot.margin = margin(15,15,15,15))

# Plot males in big sugar creek
f_e_plot <- ggplot() + 
  geom_ribbon(data = f_e, aes(x = ages, ymin = lci, ymax = uci, fill = ancestry, alpha = 0.01), show.legend = F) +
  geom_point(data = bc_f_e, aes(x = annulus, y = bc_tl), position = position_jitter(width = 0.3), fill = "grey", show.legend = F, size = 3, pch = 21, alpha = 0.6) + 
  geom_line(data = f_e, aes(x = ages, y = length, color = ancestry), size = 1, show.legend = F) +
  theme_set(theme_cowplot(12)) +
  scale_color_manual(values = c("deeppink2","deepskyblue")) +
  scale_fill_manual(values = c("grey","grey")) +
  scale_x_continuous(name = "Annulus (years)", expand = c(0,0), breaks = seq(1, 15, 1)) +
  scale_y_continuous(name = "Back-calculated total length (mm)", limits = c(0,550), breaks = seq(0, 550, 50)) +
  theme(axis.title = element_text(size = 15)) + 
  theme(axis.text = element_text(size = 15)) +
  theme(panel.border = element_rect(colour = "black", fill = NA)) +
  theme(plot.margin = margin(15,15,15,15))

# Plot males in big sugar creek
m_e_plot <- ggplot() + 
  geom_ribbon(data = m_e, aes(x = ages, ymin = lci, ymax = uci, fill = ancestry, alpha = 0.01), show.legend = F) +
  geom_point(data = bc_m_e, aes(x = annulus, y = bc_tl), position = position_jitter(width = 0.3), fill = "grey", show.legend = F, size = 3, pch = 21, alpha = 0.6) + 
  geom_line(data = m_e, aes(x = ages, y = length, color = ancestry), size = 1, show.legend = F) +
  theme_set(theme_cowplot(12)) +
  scale_color_manual(values = c("deeppink2","deepskyblue")) +
  scale_fill_manual(values = c("grey","grey")) +
  scale_x_continuous(name = "Annulus (years)", expand = c(0,0), breaks = seq(1, 15, 1)) +
  scale_y_continuous(name = "Back-calculated total length (mm)", limits = c(0,550), breaks = seq(0, 550, 50)) +
  theme(axis.title = element_text(size = 15)) + 
  theme(axis.text = element_text(size = 15)) +
  theme(panel.border = element_rect(colour = "black", fill = NA)) +
  theme(plot.margin = margin(15,15,15,15))

# Plot all von bertalanffy curves
pdf("figures/bc_predict.pdf", width = 12, height = 9)

plot_grid(f_bs_plot,
          m_bs_plot,
          f_e_plot,
          m_e_plot,
          ncol = 2,
          nrow = 2)

dev.off()
```

### STEP 2: Sensitivity analysis - von bertalanffy growth analysis using raw data.
In this step, we repeat the von Bertalanffy analysis as conducted above, but only using raw length-at-age data, to assess the sensitivity of the data (consistency between datasets, i.e., do patterns from the back-calculated data reflect what is shown by the raw data?) These data are then used as input for Bayesian hierarchical analysis. 

#### 2a: Prepare data for Bayesian hierarhical analysis; run the Rmd code below.

##### Load and prepare data for growth analysis:
```{r}
# Load full back-calculated data
load("data/bc_data/full_bc_data.Rda")

# Set rstan parameters
rstan_options(threads_per_chain = 1)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores()-1)

# Set up model matrix (sex/river) where nrow = number of ind
model_matrix <- full_bc_data %>%
  group_by(sample_id) %>%
  slice(n()) %>%
  select(sample_id, smb, river_code, sex, consensus_age, tl_alive, ancestry_group) %>%
  mutate(river_code = factor(river_code),
         sex = factor(sex)) %>%
  arrange(sample_id)

# Generate variables and match names to model 
full_bc_data <- full_bc_data %>%
  mutate(river_code = factor(river_code),
         river_code = ifelse(river_code == 3, 2, river_code),
         sex = as.numeric(factor(sex)))

age <- model_matrix$consensus_age
length <- model_matrix$tl_alive
group <- as.numeric(as.factor(model_matrix$ancestry_group)) 
sample.id <- as.numeric(as.factor(as.character(model_matrix$sample_id)))
Nind <- length(unique(sample.id))

# Define data for model
sensitivity_model_data = list(Nobs = length(length),
                              Nages = 15,
                              length = length,
                              age = age,
                              Zero = rep(0, 3),
                     
                              #Priors
                              eta_scale_prior = 0.5, 
                              cholesky_prior = 3,
                              beta_scale = 0.5,
                              Nind = Nind,
                              Ncoef = 2,
                              X = model.matrix(~ sex + river_code, model_matrix)[,2:3],
                              Xhat = matrix(c(0,0,1,0,0,1,1,1), nrow = 4, ncol = 2, byrow = TRUE),
                              q = model_matrix$smb,
                              id = sample.id)

# Save data for sensitivity growth model
save(sensitivity_model_data, file = "data/growth_model_data/sensitivity_model_data.Rda")
```

#### 2b: Run von Bertalanffy model for observed length-at-age; run the Rmd chunk below.
In this step, we use a Bayesian hierarchical framework to fit a von Bertalanffy curve to observed length-at-age data and account for SMB ancestry, sex, and stream of origin to assess the effect of SMB ancestry on growth parameters. 

##### Fit von Bertalanffy model:
```{r}
# Load data for sensitivity growth model
load("data/growth_model_data/sensitivity_model_data.Rda")

# Set MCMC specifications
control = list(adapt_delta = 0.999, 
               stepsize = 0.001, 
               max_treedepth = 18)
warmup = 6000       
thin = 2
iter = 6000    

# Run sensitivity growth model
sensitivity_model_fit <- stan(file = "code/sensitivity_model.stan",  
                              data = sensitivity_model_data,    
                              chains = 4,            
                              warmup = warmup,
                              thin = thin,
                              iter = iter * thin + warmup,     
                              cores = 4,            
                              control = control)

# Save sensitivity growth model fit output for downstream analyses
save(sensitivity_model_fit, file = "data/growth_model_data/sensitivity_model_fit.Rda")
```

#### 1c: Summarize and plot model output from von Bertalanffy growth analysis with back-calculated data.
In this step, we analyze and plot output results from the generalized linear model of the condition and ancestry proportion.

##### 1c.1. Run diagnostics on model fit; run the Rmd chunk below:

##### Model diagnostics:
```{r}
# Load back-calculated model fit output
load("data/growth_model_data/sensitivity_model_fit.Rda")

# Visually inspect chains
traceplot(sensitivity_model_fit)

# Extract summary data for model fit  
sampler_params <- get_sampler_params(sensitivity_model_fit, inc_warmup = TRUE)

# Summarize model fit
summary(do.call(rbind, sampler_params), digits = 2)


# Convergence diagnostics ----
#https://mc-stan.org/bayesplot/articles/visual-mcmc-diagnostics.html

#Posterior ll
lp_cp <- log_posterior(bc_model_fit)
head(lp_cp)

#Accepted prob
np_cp <- nuts_params(bc_model_fit)
head(np_cp)

# Look at par vs divergence
color_scheme_set("darkgray")
posterior_cp <- as.array(bc_model_fit)
mcmc_parcoord(posterior_cp, np = np_cp)

#Look at ll vs acceptance
color_scheme_set("red")
mcmc_nuts_divergence(np_cp, lp_cp)

# Print and plot MCMC ----
print(bc_model_fit, pars=c("mu_linf", "mu_k", "mu_t0", "beta_linf", "beta_k", "beta_t0", "linf_lineage", "k_lineage", "t0_lineage"), probs=c(.1,.5,.9)) # None of the betas are sig
traceplot(bc_model_fit, pars = c("mu_linf", "mu_k", "mu_t0", "sigma"), inc_warmup = FALSE, nrow = 2)
traceplot(bc_model_fit, pars = c("beta_linf", "beta_k", "beta_t0"), inc_warmup = FALSE, nrow = 2)
traceplot(bc_model_fit, pars = c("Lcorr", "sigma_group"), inc_warmup = FALSE, nrow = 2)
traceplot(bc_model_fit, pars = c("Lcorr", "sigma_ind"), inc_warmup = FALSE, nrow = 2)

pairs(bc_model_fit, pars = c("mu_linf", "mu_k", "mu_t0", "lp__"), las = 1)
pairs(bc_model_fit, pars = c("linf_lineage", "k_lineage", "t0_lineage", "lp__"), las = 1)
pairs(bc_model_fit, pars = c("beta_linf", "beta_k", "beta_t0", "lp__"), las = 1)
pairs(bc_model_fit, pars = c("sigma_group", "Lcorr", "lp__"), las = 1)
pairs(bc_model_fit, pars = c("sigma_ind", "Lcorr", "lp__"), las = 1)

# BFMI low
pairs_stan <- function(chain, stan_model, pars) {
energy <- as.matrix(sapply(get_sampler_params(stan_model, inc_warmup = F), 
                           function(x) x[,"energy__"]))
pars <- extract(stan_model, pars = pars, permuted = F)
df <- data.frame(energy[,chain], pars[,chain,])
names(df)[1] <- "energy"

GGally::ggpairs(df, title = paste0("Chain", chain), 
                lower = list(continuous = GGally::wrap("points", alpha = 0.2)))                    
 }
 
pairs_stan(1, bc_model_fit, pars = c("mu_linf", "mu_k", "mu_t0", "lp__"))
pairs_stan(1, bc_model_fit, pars = c("linf_lineage", "k_lineage", "t0_lineage", "lp__"))
pairs_stan(1, bc_model_fit, pars = c("beta_linf", "beta_k", "beta_t0", "lp__"))
pairs_stan(1, bc_model_fit, pars = c("Lcorr", "lp__"))

check_energy(bc_model_fit)

# Rhat for chain convergence
rhats <- rhat(bc_model_fit)
color_scheme_set("brightblue") # see help("color_scheme_set")
mcmc_rhat(rhats)
rhats <- data.frame(Parm = names(rhats), Rhat = rhats)

# Plot prior and posterior density distributions with custom code
source("code/plot_density.R")
plot_density(sensitivity_model_fit, file_name = "growth_analysis/figures/sensitivity_density.pdf", probs = c(0.01, 0.99))
```

##### 1c.2. Summarize mean and 95 credible intervals for all model coefficients; run the Rmd chunk below:

##### Summarize ancestry-condition fit model output:
```{r}
# Load back-calculated model fit output
load('data/growth_model_data/sensitivity_model_fit.Rda')

# Convert model fit data to dataframe
sensitivity_model_fit <- as.data.frame(sensitivity_model_fit)

# select columns with parameter estimates to summarize for analysis, and calculate posterior differences for ancestry-specific parameters
sensitivity_fixed <- sensitivity_model_fit %>%
  select(mu_linf, mu_k, mu_t0, "linf_lineage[1]", "linf_lineage[2]", "k_lineage[1]", "k_lineage[2]", "t0_lineage[1]", "t0_lineage[2]", "beta_linf[1]", "beta_linf[2]", "beta_k[1]", "beta_k[2]", "beta_t0[1]", "beta_t0[2]") %>%
  mutate(linf_diff = `linf_lineage[1]` - `linf_lineage[2]`,
         k_diff = `k_lineage[1]` - `k_lineage[2]`,
         t0_diff = `t0_lineage[1]` - `t0_lineage[2]`)

# Gather parameters and estimates at each iteration so that there are only two columns
sensitivity_fixed <- sensitivity_fixed %>%
  gather(mu_linf:t0_diff, key = "parameter", value = "estimate") %>%
  mutate(parameter = factor(parameter))

# Summarize parameter estimates and 95% credible intervals
sensitivity_fixed %>%
  group_by(parameter) %>%
  summarize(mean = mean(estimate),
            sd = sd(estimate),
            q2.5 = quantile(estimate, probs = 0.025),
            q5 = quantile(estimate, probs = 0.05), 
            q50 = quantile(estimate, probs = 0.50),
            q95 = quantile(estimate, probs = 0.95),
            q97.5 = quantile(estimate, probs = 0.975))
```

##### 1c.3. Plot 95% credible intervals for posterior differences of L∞, k, and a0 parameters; run the Rmd chunk below.

##### Plot posterior differences: `figures/sensitivity_p_diffs.pdf`
```{r}
# Load back-calculated model fit output
load('data/growth_model_data/sensitivity_model_fit.Rda')

# Convert model fit data to dataframe
sensitivity_model_fit <- as.data.frame(sensitivity_model_fit)

# select columns with parameter estimates to summarize for analysis, and calculate posterior differences for ancestry-specific parameters
sensitivity_fixed <- sensitivity_model_fit %>%
  select(mu_linf, mu_k, mu_t0, "linf_lineage[1]", "linf_lineage[2]", "k_lineage[1]", "k_lineage[2]", "t0_lineage[1]", "t0_lineage[2]", "beta_linf[1]", "beta_linf[2]", "beta_k[1]", "beta_k[2]", "beta_t0[1]", "beta_t0[2]") %>%
  mutate(linf_diff = `linf_lineage[1]` - `linf_lineage[2]`,
         k_diff = `k_lineage[1]` - `k_lineage[2]`,
         t0_diff = `t0_lineage[1]` - `t0_lineage[2]`)

# Gather parameters and estimates at each iteration so that there are only two columns
sensitivity_fixed <- sensitivity_fixed %>%
  gather(mu_linf:t0_diff, key = "parameter", value = "estimate") %>%
  mutate(parameter = factor(parameter))

# Select only linf difference parameter for plotting
linf_p_diffs <- sensitivity_fixed %>%
  filter(parameter == "linf_diff")

# Select only k difference parameter for plotting
k_p_diffs <- sensitivity_fixed %>%
  filter(parameter == "k_diff")

# Select only t0 difference parameter for plotting
t0_p_diffs <- sensitivity_fixed %>%
  filter(parameter == "t0_diff")

# Get posterior difference parameter plots
linf <- ggplot(linf_p_diffs, aes(x = parameter, y = estimate)) +
  geom_boxplot(fill = "grey") +
  theme_set(theme_cowplot(12)) +
  labs(x = "Parameter", y = "Estimate") + 
  geom_hline(yintercept = 0, size = 1, linetype = "longdash", color = "red") +
  theme(axis.text = element_text(size = 15)) +
  theme(axis.title = element_blank()) + 
  theme(axis.text.x = element_blank()) +
  theme(panel.border = element_rect(colour = "black", fill = NA)) +
  theme(plot.margin = margin(10,10,10,10))

# Get posterior difference parameter plots
k <- ggplot(k_p_diffs, aes(x = parameter, y = estimate)) +
  geom_boxplot(fill = "grey") +
  theme_set(theme_cowplot(12)) +
  labs(x = "Parameter", y = "Estimate") + 
  geom_hline(yintercept = 0, size = 1, linetype = "longdash", color = "red") +
  theme(axis.text = element_text(size = 15)) +
  theme(axis.title = element_blank()) + 
  theme(axis.text.x = element_blank()) +
  theme(panel.border = element_rect(colour = "black", fill = NA)) +
  theme(plot.margin = margin(10,10,10,10))

# Get posterior difference parameter plots
t0 <- ggplot(t0_p_diffs, aes(x = parameter, y = estimate)) +
  geom_boxplot(fill = "grey") +
  theme_set(theme_cowplot(12)) +
  labs(x = "Parameter", y = "Estimate") + 
  geom_hline(yintercept = 0, size = 1, linetype = "longdash", color = "red") +
  theme(axis.text = element_text(size = 15)) +
  theme(axis.title = element_blank()) + 
  theme(axis.text.x = element_blank()) +
  theme(panel.border = element_rect(colour = "black", fill = NA)) +
  theme(plot.margin = margin(10,10,10,10))

# Plot posterior difference 95% CIs
pdf("figures/sensitivity_p_diffs.pdf", width = 9, height = 5)

plot_grid(linf,
          k,
          t0,
          nrow = 1,
          ncol = 3)

dev.off()
```

##### 1c.4. Plot 95% credible intervals for beta coefficient posterior densities of L∞, k, and a0 parameters for sex and stream; run the Rmd chunk below.

##### Plot sensitivity posterior differences: 1) `figures/sensitivity_sex_betas.pdf`, 2) `figures/sensitivity_stream_betas.pdf`
```{r}
# Load back-calculated model fit output
load('data/growth_model_data/sensitivity_model_fit.Rda')

# Convert model fit data to dataframe
sensitivity_model_fit <- as.data.frame(sensitivity_model_fit)

# select columns with parameter estimates to summarize for analysis, and calculate posterior differences for ancestry-specific parameters
sensitivity_fixed <- sensitivity_model_fit %>%
  select(mu_linf, mu_k, mu_t0, "linf_lineage[1]", "linf_lineage[2]", "k_lineage[1]", "k_lineage[2]", "t0_lineage[1]", "t0_lineage[2]", "beta_linf[1]", "beta_linf[2]", "beta_k[1]", "beta_k[2]", "beta_t0[1]", "beta_t0[2]") %>%
  mutate(linf_diff = `linf_lineage[1]` - `linf_lineage[2]`,
         k_diff = `k_lineage[1]` - `k_lineage[2]`,
         t0_diff = `t0_lineage[1]` - `t0_lineage[2]`)

# Gather parameters and estimates at each iteration so that there are only two columns
sensitivity_fixed <- sensitivity_fixed %>%
  gather(mu_linf:t0_diff, key = "parameter", value = "estimate") %>%
  mutate(parameter = factor(parameter))

# Select only posterior densities for stream- and sex-specific fixed effects
stream_sex_betas <- bc_fixed %>%
  filter(parameter == "beta_linf[1]" |
           parameter == "beta_linf[2]" |
           parameter == "beta_k[1]" |
           parameter == "beta_k[2]" |
           parameter == "beta_t0[1]" |
           parameter == "beta_t0[2]")

# Add column in beta table to describe parameter type (linf, k, and t0) for facet wrapping in plot
stream_sex_betas$variable <- factor(c(rep("Sex", times = 24000), 
                                      rep("Stream", times = 24000), 
                                      rep("Sex", times = 24000), 
                                      rep("Stream", times = 24000), 
                                      rep("Sex", times = 24000), 
                                      rep("Stream", times = 24000)))

# Get only betas for sex
sex_betas <- stream_sex_betas %>%
  filter(variable == "Sex")

# Get only betas for stream 
stream_betas <- stream_sex_betas %>%
  filter(variable == "Stream")

# Put parameters in desired order to show up on graph (linf, then k, then t0)
sex_betas$parameter <- factor(sex_betas$parameter, levels = c("beta_linf[1]", "beta_k[1]", "beta_t0[1]"))

# Put parameters in desired order to show up on graph (linf, then k, then t0)
stream_betas$parameter <- factor(stream_betas$parameter, levels = c("beta_linf[2]", "beta_k[2]", "beta_t0[2]"))

# Plot sex beta coefficient 95% CIs
pdf("figures/sensitivity_sex_betas.pdf", width = 7, height = 5)

ggplot(sex_betas, aes(x = parameter, y = estimate)) +
  geom_boxplot(fill = "grey") +
  theme_set(theme_cowplot(12)) +
  labs(x = "Parameter", y = "Estimate") + 
  geom_hline(yintercept = 0, size = 1, linetype = "longdash", color = "red") +
  theme(axis.text = element_text(size = 15)) +
  theme(axis.title = element_text(size = 15)) + 
  theme(axis.text.x = element_blank()) +
  theme(panel.border = element_rect(colour = "black", fill = NA)) +
  theme(plot.margin = margin(10,10,10,10))

dev.off()

# Plot sex beta coefficient 95% CIs
pdf("figures/sensitivity_stream_betas.pdf", width = 7, height = 5)

ggplot(stream_betas, aes(x = parameter, y = estimate)) +
  geom_boxplot(fill = "grey") +
  theme_set(theme_cowplot(12)) +
  labs(x = "Parameter", y = "Estimate") + 
  geom_hline(yintercept = 0, size = 1, linetype = "longdash", color = "red") +
  theme(axis.text = element_text(size = 15)) +
  theme(axis.title = element_text(size = 15)) + 
  theme(axis.text.x = element_blank()) +
  theme(panel.border = element_rect(colour = "black", fill = NA)) +
  theme(plot.margin = margin(10,10,10,10))

dev.off()
```

##### 1c.5. Plot predicted observed using calculated parameter values; run the Rmd chunk below.

##### Plot predicted observed length-at-age prediction: `figures/sensitivity_predict.pdf`
```{r}
# Load sensitivity model fit output
load('data/growth_model_data/sensitivity_model_fit.Rda')

# Load data for sensitivity growth model
load("data/growth_model_data/sensitivity_model_data.Rda")

# Load observed data
load("data/bc_data/full_bc_data.Rda")

# Convert model fit data to dataframe
sensitivity_model_fit <- as.data.frame(sensitivity_model_fit)

# Get sequence of ages
ages <- seq(1, 15, 1)

# Generate empty matrix to hold predicted length values up to 15 annuli for female SMB from Big Sugar Creek
f_bs_smb_predicted_length <- matrix(NA,
                                    length(sensitivity_model_fit$mu_linf), 
                                    length(ages)) 

# Generate empty matrix to hold predicted length values up to 15 annuli for female NB from Big Sugar Creek
f_bs_nb_predicted_length <- matrix(NA,
                                   length(sensitivity_model_fit$mu_linf), 
                                   length(ages)) 

# Generate empty matrix to hold predicted length values up to 15 annuli for female SMB from Elk River
f_e_smb_predicted_length <- matrix(NA, 
                                   length(sensitivity_model_fit$mu_linf), 
                                   length(ages)) 

# Generate empty matrix to hold predicted length values up to 15 annuli for female NB from Elk River
f_e_nb_predicted_length <- matrix(NA, 
                                  length(sensitivity_model_fit$mu_linf),
                                  length(ages)) 


# Generate empty matrix to hold predicted length values up to 15 annuli for male SMB from Big Sugar Creek
m_bs_smb_predicted_length <- matrix(NA,
                                    length(sensitivity_model_fit$mu_linf), 
                                    length(ages)) 

# Generate empty matrix to hold predicted length values up to 15 annuli for male NB from Big Sugar Creek
m_bs_nb_predicted_length <- matrix(NA, 
                                   length(sensitivity_model_fit$mu_linf), 
                                   length(ages)) 

# Generate empty matrix to hold predicted length values up to 15 annuli for male SMB from Elk River
m_e_smb_predicted_length <- matrix(NA, 
                                   length(sensitivity_model_fit$mu_linf), 
                                   length(ages)) 

# Generate empty matrix to hold predicted length values up to 15 annuli for male NB from Elk River
m_e_nb_predicted_length <- matrix(NA, 
                                  length(sensitivity_model_fit$mu_linf), 
                                  length(ages)) 

# Fill empty matrix for female SMB from Big Sugar Creek
for (i in 1:length(ages)) { # fill empty matrix with predicted values using the model
   f_bs_smb_predicted_length[,i] = sensitivity_model_fit$`pred_linf[1]` * exp(sensitivity_model_fit$eta_smb_linf) * (1 - exp(-sensitivity_model_fit$`pred_k[1]` * exp(sensitivity_model_fit$eta_smb_k) * (i - sensitivity_model_fit$`pred_t0[1]` - sensitivity_model_fit$eta_smb_t0)))

}

# Fill empty matrix for female NB from Big Sugar Creek
for (i in 1:length(ages)) { # fill empty matrix with predicted values using the model
   f_bs_nb_predicted_length[,i] = sensitivity_model_fit$`pred_linf[1]` * exp(sensitivity_model_fit$eta_n_linf) * (1 - exp(-sensitivity_model_fit$`pred_k[1]` * exp(sensitivity_model_fit$eta_n_k) * (i - sensitivity_model_fit$`pred_t0[1]` - sensitivity_model_fit$eta_n_t0)))

}

# Fill empty matrix for female SMB from Elk River
for (i in 1:length(ages)) { # fill empty matrix with predicted values using the model
   f_e_smb_predicted_length[,i] = sensitivity_model_fit$`pred_linf[3]` * exp(sensitivity_model_fit$eta_smb_linf) * (1 - exp(-sensitivity_model_fit$`pred_k[3]` * exp(sensitivity_model_fit$eta_smb_k) * (i - sensitivity_model_fit$`pred_t0[3]` - sensitivity_model_fit$eta_smb_t0)))

}

# Fill empty matrix for female NB from Elk River
for (i in 1:length(ages)) { # fill empty matrix with predicted values using the model
   f_e_nb_predicted_length[,i] = sensitivity_model_fit$`pred_linf[3]` * exp(sensitivity_model_fit$eta_n_linf) * (1 - exp(-sensitivity_model_fit$`pred_k[3]` * exp(sensitivity_model_fit$eta_n_k) * (i - sensitivity_model_fit$`pred_t0[3]` - sensitivity_model_fit$eta_n_t0)))

}

# Fill empty matrix for male SMB from Big Sugar Creek
for (i in 1:length(ages)) { # fill empty matrix with predicted values using the model
   m_bs_smb_predicted_length[,i] = sensitivity_model_fit$`pred_linf[2]` * exp(sensitivity_model_fit$eta_smb_linf) * (1 - exp(-sensitivity_model_fit$`pred_k[2]` * exp(sensitivity_model_fit$eta_smb_k) * (i - sensitivity_model_fit$`pred_t0[2]` - sensitivity_model_fit$eta_smb_t0)))

}

# Fill empty matrix for male NB from Big Sugar Creek
for (i in 1:length(ages)) { # fill empty matrix with predicted values using the model
   m_bs_nb_predicted_length[,i] = sensitivity_model_fit$`pred_linf[2]` * exp(sensitivity_model_fit$eta_n_linf) * (1 - exp(-sensitivity_model_fit$`pred_k[2]` * exp(sensitivity_model_fit$eta_n_k) * (i - sensitivity_model_fit$`pred_t0[2]` - sensitivity_model_fit$eta_n_t0)))

}

# Fill empty matrix for male SMB from Elk River
for (i in 1:length(ages)) { # fill empty matrix with predicted values using the model
   m_e_smb_predicted_length[,i] = sensitivity_model_fit$`pred_linf[4]` * exp(sensitivity_model_fit$eta_smb_linf) * (1 - exp(-sensitivity_model_fit$`pred_k[4]` * exp(sensitivity_model_fit$eta_smb_k) * (i - sensitivity_model_fit$`pred_t0[4]` -sensitivity_model_fit$eta_smb_t0)))

}

# Fill empty matrix for male NB from Elk River
for (i in 1:length(ages)) { # fill empty matrix with predicted values using the model
   m_e_nb_predicted_length[,i] = sensitivity_model_fit$`pred_linf[4]` * exp(sensitivity_model_fit$eta_n_linf) * (1 - exp(-sensitivity_model_fit$`pred_k[4]`* exp(sensitivity_model_fit$eta_n_k) * (i - sensitivity_model_fit$`pred_t0[4]` -sensitivity_model_fit$eta_n_t0)))

}

# Get numeric vectors to hold means and credible interval estimates from predictions
f_bs_smb_mean_length <- f_bs_smb_uci_length <- f_bs_smb_lci_length <- numeric()
f_bs_nb_mean_length <- f_bs_nb_uci_length <- f_bs_nb_lci_length <- numeric()
f_e_smb_mean_length <- f_e_smb_uci_length <- f_e_smb_lci_length <- numeric()
f_e_nb_mean_length <- f_e_nb_uci_length <- f_e_nb_lci_length <- numeric()
m_bs_smb_mean_length <- m_bs_smb_uci_length <- m_bs_smb_lci_length <- numeric()
m_bs_nb_mean_length <- m_bs_nb_uci_length <- m_bs_nb_lci_length <- numeric()
m_e_smb_mean_length <- m_e_smb_uci_length <- m_e_smb_lci_length <- numeric()
m_e_nb_mean_length <- m_e_nb_uci_length <- m_e_nb_lci_length <- numeric()

# Predict mean and confidence intervals around trendline for female SMB from Big Sugar Creek
for (i in 1:length(ages)){
  f_bs_smb_mean_length[i] <- mean(f_bs_smb_predicted_length[,i]) 
  f_bs_smb_uci_length[i] <- quantile(f_bs_smb_predicted_length[,i], probs=0.975)
  f_bs_smb_lci_length[i] <- quantile(f_bs_smb_predicted_length[,i], probs=0.025)
}

# Generate dataframes for each vector
f_bs_smb_mean_length <- as.data.frame(f_bs_smb_mean_length)
f_bs_smb_uci_length <- as.data.frame(f_bs_smb_uci_length)
f_bs_smb_lci_length <- as.data.frame(f_bs_smb_lci_length)

# Change column names
colnames(f_bs_smb_mean_length) <- c("length")
colnames(f_bs_smb_uci_length) <- c("uci")
colnames(f_bs_smb_lci_length) <- c("lci")

# Add additional descriptor columns for ancestry, sex, and stream
f_bs_smb_lci_length$ancestry <- factor(rep("SMB", times = 15))
f_bs_smb_lci_length$sex <- factor(rep("Female", times = 15))
f_bs_smb_lci_length$stream <- factor(rep("Big Sugar Creek", times = 15))

# Bind mean, uci, and lci columns together
f_bs_smb <- cbind(ages,
                  f_bs_smb_mean_length,
                  f_bs_smb_uci_length,
                  f_bs_smb_lci_length)

# Predict mean and confidence intervals around trendline for female NB from Big Sugar Creek
for (i in 1:length(ages)){
  f_bs_nb_mean_length[i] <- mean(f_bs_nb_predicted_length[,i]) 
  f_bs_nb_uci_length[i] <- quantile(f_bs_nb_predicted_length[,i], probs=0.975)
  f_bs_nb_lci_length[i] <- quantile(f_bs_nb_predicted_length[,i], probs=0.025)
}

# Generate dataframes for each vector
f_bs_nb_mean_length <- as.data.frame(f_bs_nb_mean_length)
f_bs_nb_uci_length <- as.data.frame(f_bs_nb_uci_length)
f_bs_nb_lci_length <- as.data.frame(f_bs_nb_lci_length)

# Change column names
colnames(f_bs_nb_mean_length) <- c("length")
colnames(f_bs_nb_uci_length) <- c("uci")
colnames(f_bs_nb_lci_length) <- c("lci")

# Add additional descriptor columns for ancestry, sex, and stream
f_bs_nb_lci_length$ancestry <- factor(rep("NB", times = 15))
f_bs_nb_lci_length$sex <- factor(rep("Female", times = 15))
f_bs_nb_lci_length$stream <- factor(rep("Big Sugar Creek", times = 15))

# Bind mean, uci, and lci columns together
f_bs_nb <- cbind(ages,
                 f_bs_nb_mean_length,
                 f_bs_nb_uci_length,
                 f_bs_nb_lci_length)

# Predict mean and confidence intervals around trendline for female SMB from Elk River
for (i in 1:length(ages)){
  f_e_smb_mean_length[i] <- mean(f_e_smb_predicted_length[,i]) 
  f_e_smb_uci_length[i] <- quantile(f_e_smb_predicted_length[,i], probs=0.975)
  f_e_smb_lci_length[i] <- quantile(f_e_smb_predicted_length[,i], probs=0.025)
}

# Generate dataframes for each vector
f_e_smb_mean_length <- as.data.frame(f_e_smb_mean_length)
f_e_smb_uci_length <- as.data.frame(f_e_smb_uci_length)
f_e_smb_lci_length <- as.data.frame(f_e_smb_lci_length)

# Change column names
colnames(f_e_smb_mean_length) <- c("length")
colnames(f_e_smb_uci_length) <- c("uci")
colnames(f_e_smb_lci_length) <- c("lci")

# Add additional descriptor columns for ancestry, sex, and stream
f_e_smb_lci_length$ancestry <- factor(rep("SMB", times = 15))
f_e_smb_lci_length$sex <- factor(rep("Female", times = 15))
f_e_smb_lci_length$stream <- factor(rep("Elk River", times = 15))

# Bind mean, uci, and lci columns together
f_e_smb <- cbind(ages,
                 f_e_smb_mean_length,
                 f_e_smb_uci_length,
                 f_e_smb_lci_length)

# Predict mean and confidence intervals around trendline for female NB from Elk River
for (i in 1:length(ages)){
  f_e_nb_mean_length[i] <- mean(f_e_nb_predicted_length[,i]) 
  f_e_nb_uci_length[i] <- quantile(f_e_nb_predicted_length[,i], probs=0.975)
  f_e_nb_lci_length[i] <- quantile(f_e_nb_predicted_length[,i], probs=0.025)
}

# Generate dataframes for each vector
f_e_nb_mean_length <- as.data.frame(f_e_nb_mean_length)
f_e_nb_uci_length <- as.data.frame(f_e_nb_uci_length)
f_e_nb_lci_length <- as.data.frame(f_e_nb_lci_length)

# Change column names
colnames(f_e_nb_mean_length) <- c("length")
colnames(f_e_nb_uci_length) <- c("uci")
colnames(f_e_nb_lci_length) <- c("lci")

# Add additional descriptor columns for ancestry, sex, and stream
f_e_nb_lci_length$ancestry <- factor(rep("NB", times = 15))
f_e_nb_lci_length$sex <- factor(rep("Female", times = 15))
f_e_nb_lci_length$stream <- factor(rep("Elk River", times = 15))

# Bind mean, uci, and lci columns together
f_e_nb <- cbind(ages,
                f_e_nb_mean_length,
                f_e_nb_uci_length,
                f_e_nb_lci_length)

# Predict mean and confidence intervals around trendline for male SMB from Big Sugar Creek
for (i in 1:length(ages)){
  m_bs_smb_mean_length[i] <- mean(m_bs_smb_predicted_length[,i]) 
  m_bs_smb_uci_length[i] <- quantile(m_bs_smb_predicted_length[,i], probs=0.975)
  m_bs_smb_lci_length[i] <- quantile(m_bs_smb_predicted_length[,i], probs=0.025)
}

# Generate dataframes for each vector
m_bs_smb_mean_length <- as.data.frame(m_bs_smb_mean_length)
m_bs_smb_uci_length <- as.data.frame(m_bs_smb_uci_length)
m_bs_smb_lci_length <- as.data.frame(m_bs_smb_lci_length)

# Change column names
colnames(m_bs_smb_mean_length) <- c("length")
colnames(m_bs_smb_uci_length) <- c("uci")
colnames(m_bs_smb_lci_length) <- c("lci")

# Add additional descriptor columns for ancestry, sex, and stream
m_bs_smb_lci_length$ancestry <- factor(rep("SMB", times = 15))
m_bs_smb_lci_length$sex <- factor(rep("Male", times = 15))
m_bs_smb_lci_length$stream <- factor(rep("Big Sugar Creek", times = 15))

# Bind mean, uci, and lci columns together
m_bs_smb <- cbind(ages,
                  m_bs_smb_mean_length,
                  m_bs_smb_uci_length,
                  m_bs_smb_lci_length)

# Predict mean and confidence intervals around trendline for male NB from Big Sugar Creek
for (i in 1:length(ages)){
  m_bs_nb_mean_length[i] <- mean(m_bs_nb_predicted_length[,i]) 
  m_bs_nb_uci_length[i] <- quantile(m_bs_nb_predicted_length[,i], probs=0.975)
  m_bs_nb_lci_length[i] <- quantile(m_bs_nb_predicted_length[,i], probs=0.025)
}

# Generate dataframes for each vector
m_bs_nb_mean_length <- as.data.frame(m_bs_nb_mean_length)
m_bs_nb_uci_length <- as.data.frame(m_bs_nb_uci_length)
m_bs_nb_lci_length <- as.data.frame(m_bs_nb_lci_length)

# Change column names
colnames(m_bs_nb_mean_length) <- c("length")
colnames(m_bs_nb_uci_length) <- c("uci")
colnames(m_bs_nb_lci_length) <- c("lci")

# Add additional descriptor columns for ancestry, sex, and stream
m_bs_nb_lci_length$ancestry <- factor(rep("NB", times = 15))
m_bs_nb_lci_length$sex <- factor(rep("Male", times = 15))
m_bs_nb_lci_length$stream <- factor(rep("Big Sugar Creek", times = 15))

# Bind mean, uci, and lci columns together
m_bs_nb <- cbind(ages,
                 m_bs_nb_mean_length,
                 m_bs_nb_uci_length,
                 m_bs_nb_lci_length)

# Predict mean and confidence intervals around trendline for male SMB from Elk River
for (i in 1:length(ages)){
  m_e_smb_mean_length[i] <- mean(m_e_smb_predicted_length[,i]) 
  m_e_smb_uci_length[i] <- quantile(m_e_smb_predicted_length[,i], probs=0.975)
  m_e_smb_lci_length[i] <- quantile(m_e_smb_predicted_length[,i], probs=0.025)
}

# Generate dataframes for each vector
m_e_smb_mean_length <- as.data.frame(m_e_smb_mean_length)
m_e_smb_uci_length <- as.data.frame(m_e_smb_uci_length)
m_e_smb_lci_length <- as.data.frame(m_e_smb_lci_length)

# Change column names
colnames(m_e_smb_mean_length) <- c("length")
colnames(m_e_smb_uci_length) <- c("uci")
colnames(m_e_smb_lci_length) <- c("lci")

# Add additional descriptor columns for ancestry, sex, and stream
m_e_smb_lci_length$ancestry <- factor(rep("SMB", times = 15))
m_e_smb_lci_length$sex <- factor(rep("Male", times = 15))
m_e_smb_lci_length$stream <- factor(rep("Elk River", times = 15))

# Bind mean, uci, and lci columns together
m_e_smb <- cbind(ages,
                 m_e_smb_mean_length,
                 m_e_smb_uci_length,
                 m_e_smb_lci_length)

# Predict mean and confidence intervals around trendline for male NB from Elk River
for (i in 1:length(ages)){
  m_e_nb_mean_length[i] <- mean(m_e_nb_predicted_length[,i]) 
  m_e_nb_uci_length[i] <- quantile(m_e_nb_predicted_length[,i], probs=0.975)
  m_e_nb_lci_length[i] <- quantile(m_e_nb_predicted_length[,i], probs=0.025)
}

# Generate dataframes for each vector
m_e_nb_mean_length <- as.data.frame(m_e_nb_mean_length)
m_e_nb_uci_length <- as.data.frame(m_e_nb_uci_length)
m_e_nb_lci_length <- as.data.frame(m_e_nb_lci_length)

# Change column names
colnames(m_e_nb_mean_length) <- c("length")
colnames(m_e_nb_uci_length) <- c("uci")
colnames(m_e_nb_lci_length) <- c("lci")

# Add additional descriptor columns for ancestry, sex, and stream
m_e_nb_lci_length$ancestry <- factor(rep("NB", times = 15))
m_e_nb_lci_length$sex <- factor(rep("Male", times = 15))
m_e_nb_lci_length$stream <- factor(rep("Elk River", times = 15))

# Bind mean, uci, and lci columns together
m_e_nb <- cbind(ages,
                m_e_nb_mean_length,
                m_e_nb_uci_length,
                m_e_nb_lci_length)
  
# Bind all data frames together by row
sensitivity_predict <- rbind(f_bs_smb,
                             f_bs_nb,
                             f_e_smb,
                             f_e_nb,
                             m_bs_smb,
                             m_bs_nb,
                             m_e_smb,
                             m_e_nb)

# Get dataframe for females in Big Sugar Creek
f_bs <- sensitivity_predict %>%
  filter(sex == "Female" & stream == "Big Sugar Creek")

# Get dataframe for males in Big Sugar Creek
m_bs <- sensitivity_predict %>%
  filter(sex == "Male" & stream == "Big Sugar Creek")

# Get dataframe for females in Elk River
f_e <- sensitivity_predict %>%
  filter(sex == "Female" & stream == "Elk River")

# Get dataframe for males in Elk River
m_e <- sensitivity_predict %>%
  filter(sex == "Male" & stream == "Elk River")

# Get raw data for females in Big Sugar Creek
obs_f_bs <- full_bc_data %>%
  group_by(sample_id) %>%
  slice(n()) %>%
  filter(sex == "Female" & river == "Big_Sugar")

# Get raw data for males in Big Sugar Creek
obs_m_bs <- full_bc_data %>%
  group_by(sample_id) %>%
  slice(n()) %>%
  filter(sex == "Male" & river == "Big_Sugar")

# Get raw data for females in Elk River
obs_f_e <- full_bc_data %>%
  group_by(sample_id) %>%
  slice(n()) %>%
  filter(sex == "Female" & river == "Elk_River")

# Get raw data for males in Elk River
obs_m_e <- full_bc_data %>%
  group_by(sample_id) %>%
  slice(n()) %>%
  filter(sex == "Male" & river == "Elk_River")


# Plot females in big sugar creek
f_bs_plot <- ggplot() + 
  geom_ribbon(data = f_bs, aes(x = ages, ymin = lci, ymax = uci, fill = ancestry, alpha = 0.01), show.legend = F) +
  geom_point(data = obs_f_bs, aes(x = annulus, y = bc_tl), position = position_jitter(width = 0.3), fill = "grey", show.legend = F, size = 3, pch = 21, alpha = 0.6) + 
  geom_line(data = f_bs, aes(x = ages, y = length, color = ancestry), size = 1, show.legend = F) +
  theme_set(theme_cowplot(12)) +
  scale_color_manual(values = c("deeppink2","deepskyblue")) +
  scale_fill_manual(values = c("grey","grey")) +
  scale_x_continuous(name = "Annulus (years)", expand = c(0,0), breaks = seq(1, 15, 1)) +
  scale_y_continuous(name = "Back-calculated total length (mm)", limits = c(0,700), breaks = seq(0, 700, 100)) +
  theme(axis.title = element_text(size = 15)) + 
  theme(axis.text = element_text(size = 15)) +
  theme(panel.border = element_rect(colour = "black", fill = NA)) +
  theme(plot.margin = margin(15,15,15,15))

# Plot males in big sugar creek
m_bs_plot <- ggplot() + 
  geom_ribbon(data = m_bs, aes(x = ages, ymin = lci, ymax = uci, fill = ancestry, alpha = 0.01), show.legend = F) +
  geom_point(data = obs_m_bs, aes(x = annulus, y = bc_tl), position = position_jitter(width = 0.3), fill = "grey", show.legend = F, size = 3, pch = 21, alpha = 0.6) + 
  geom_line(data = m_bs, aes(x = ages, y = length, color = ancestry), size = 1, show.legend = F) +
  theme_set(theme_cowplot(12)) +
  scale_color_manual(values = c("deeppink2","deepskyblue")) +
  scale_fill_manual(values = c("grey","grey")) +
  scale_x_continuous(name = "Annulus (years)", expand = c(0,0), breaks = seq(1, 15, 1)) +
  scale_y_continuous(name = "Back-calculated total length (mm)", limits = c(0,700), breaks = seq(0, 700, 100)) +
  theme(axis.title = element_text(size = 15)) + 
  theme(axis.text = element_text(size = 15)) +
  theme(panel.border = element_rect(colour = "black", fill = NA)) +
  theme(plot.margin = margin(15,15,15,15))

# Plot males in big sugar creek
f_e_plot <- ggplot() + 
  geom_ribbon(data = f_e, aes(x = ages, ymin = lci, ymax = uci, fill = ancestry, alpha = 0.01), show.legend = F) +
  geom_point(data = obs_f_e, aes(x = annulus, y = bc_tl), position = position_jitter(width = 0.3), fill = "grey", show.legend = F, size = 3, pch = 21, alpha = 0.6) + 
  geom_line(data = f_e, aes(x = ages, y = length, color = ancestry), size = 1, show.legend = F) +
  theme_set(theme_cowplot(12)) +
  scale_color_manual(values = c("deeppink2","deepskyblue")) +
  scale_fill_manual(values = c("grey","grey")) +
  scale_x_continuous(name = "Annulus (years)", expand = c(0,0), breaks = seq(1, 15, 1)) +
  scale_y_continuous(name = "Back-calculated total length (mm)", limits = c(0,700), breaks = seq(0, 700, 100)) +
  theme(axis.title = element_text(size = 15)) + 
  theme(axis.text = element_text(size = 15)) +
  theme(panel.border = element_rect(colour = "black", fill = NA)) +
  theme(plot.margin = margin(15,15,15,15))

# Plot males in big sugar creek
m_e_plot <- ggplot() + 
  geom_ribbon(data = m_e, aes(x = ages, ymin = lci, ymax = uci, fill = ancestry, alpha = 0.01), show.legend = F) +
  geom_point(data = obs_m_e, aes(x = annulus, y = bc_tl), position = position_jitter(width = 0.3), fill = "grey", show.legend = F, size = 3, pch = 21, alpha = 0.6) + 
  geom_line(data = m_e, aes(x = ages, y = length, color = ancestry), size = 1, show.legend = F) +
  theme_set(theme_cowplot(12)) +
  scale_color_manual(values = c("deeppink2","deepskyblue")) +
  scale_fill_manual(values = c("grey","grey")) +
  scale_x_continuous(name = "Annulus (years)", expand = c(0,0), breaks = seq(1, 15, 1)) +
  scale_y_continuous(name = "Back-calculated total length (mm)", limits = c(0,700), breaks = seq(0, 700, 100)) +
  theme(axis.title = element_text(size = 15)) + 
  theme(axis.text = element_text(size = 15)) +
  theme(panel.border = element_rect(colour = "black", fill = NA)) +
  theme(plot.margin = margin(15,15,15,15))

# Plot all von bertalanffy curves
pdf("figures/sensitivity_predict.pdf", width = 12, height = 9)

plot_grid(f_bs_plot,
          m_bs_plot,
          f_e_plot,
          m_e_plot,
          ncol = 2,
          nrow = 2)

dev.off()
```

### ----------------------- END OF PHASE 2: VON BERTALANFFY GROWTH ANALYSIS ----------------------- ###

### ----------------------- END OF ANALYSIS 4: VON BERTALANFFY GROWTH ANALYSIS ----------------------- ###


